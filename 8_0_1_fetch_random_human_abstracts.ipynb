{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Retrieve close and distant articles vs RDoC terms.\n",
    "\n",
    "We want articles that are distant to, and increasingly close to the RDoC terms we are using.\n",
    "\n",
    "These will serve as 'negative' article examples for a negative training set for deepdive.\n",
    "\n",
    "The negative articles will help establish:\n",
    "- DeepDive **response to distance** of negative training set vs. term of interest articles.\n",
    "- DeepDive **response to increasing depth** of negative training set.\n",
    "\n",
    "## Some notes on using MESH in searches\n",
    "(See appendix for additional resources)\n",
    "\n",
    "Using the MESH terms only is too harsh strict for major category terms.\n",
    "\n",
    "Following search generated by entering pubmed search: human AND \n",
    "\n",
    "(psychology or psychiatry):\n",
    "\n",
    "- ((\"psychology\"[Subheading] OR \"psychology\"[All Fields] OR \"psychology\"[MeSH Terms]) OR (\"psychiatry\"[MeSH Terms] OR \"psychiatry\"[All Fields])) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "- 318188\n",
    "\n",
    "human AND (psychology or psychiatry):\n",
    "\n",
    "- ((\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND ((\"psychology\"[Subheading] OR \"psychology\"[All Fields] OR \"psychology\"[MeSH Terms]) OR (\"psychiatry\"[MeSH Terms] OR \"psychiatry\"[All Fields]))) AND (hasabstract[text] AND \"2011/01/31\"[PDAT] : \"2016/01/29\"[PDAT]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "- 249889\n",
    "\n",
    "human AND disease:\n",
    "- ((\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND (\"disease\"[MeSH Terms] OR \"disease\"[All Fields])) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "- 579517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp: File exists\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp\n"
     ]
    }
   ],
   "source": [
    "dest_dir = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp'\n",
    "%mkdir {dest_dir}\n",
    "%cd {dest_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previous pmids already retrieved.\n",
    "# #from __future__ import print_function\n",
    "# import glob\n",
    "# import os\n",
    "# import re\n",
    "# prev_annotated_pdfs_dir = '/Users/ccarey/Documents/Projects/NAMI/rdoc/pdfs/all_pdfs_annotated_pmid_names/*.pdf'\n",
    "# pdfs = glob.glob(prev_annotated_pdfs_dir)\n",
    "# pdfs = [os.path.basename(pdf) for pdf in pdfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from Bio import Entrez\n",
    "from subprocess import check_call\n",
    "from shutil import copy2\n",
    "Entrez.email = \"charlieccarey@gmail.com\"\n",
    "\n",
    "def narrow_id_list(found_ids, omit_ids):\n",
    "    found_but_omit = list(set(found_ids) & set(omit_ids))\n",
    "    found_and_keep = list(set(found_ids) - set(omit_ids))\n",
    "    print('Removed this many ids: {}'.format(len(found_but_omit)))\n",
    "    return(found_and_keep)\n",
    "\n",
    "def pubmed_central_search_to_pubmed_id(search_string, retmax=20):\n",
    "    # verify how many records match\n",
    "    handle = Entrez.egquery(term=search_string)\n",
    "    record = Entrez.read(handle)\n",
    "    # maybe useful if we are dealing with 100s of ids and don't want to overwhelm server?\n",
    "    for row in record[\"eGQueryResult\"]:\n",
    "        if row[\"DbName\"] == \"pubmed\":\n",
    "            print(row[\"Count\"])\n",
    "    # fetch the ids for those records\n",
    "    handle = Entrez.esearch(db=\"pubmed\", retmax=retmax, term=search_string)\n",
    "    record = Entrez.read(handle)\n",
    "    pubmed_ids = record[\"IdList\"]\n",
    "    return(pubmed_ids)\n",
    "\n",
    "def search_and_summarize(search_name, query, omit_ids=None):\n",
    "    ids = pubmed_central_search_to_pubmed_id(query, retmax=1000000)\n",
    "    if omit_ids is not None:\n",
    "        new_ids = narrow_id_list(ids, omit_ids)\n",
    "    else:\n",
    "        new_ids = ids\n",
    "    print('{} search of pubmed found {} ids of which {} are new'.format(search_name, len(ids), len(new_ids)))\n",
    "    return(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AR00 = '(\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND (\"arousal\"[All Fields] OR \"arousal\"[MeSH Terms]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])'\n",
    "AP00 = '(\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND (\"auditory perception\"[All Fields] OR \"auditory perception\"[MeSH Terms]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])'\n",
    "psych = '((\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND ((\"psychology\"[Subheading] OR \"psychology\"[All Fields] OR \"psychology\"[MeSH Terms]) OR (\"psychiatry\"[MeSH Terms] OR \"psychiatry\"[All Fields]))) AND (hasabstract[text] AND \"2011/01/31\"[PDAT] : \"2016/01/29\"[PDAT]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])'\n",
    "disease = '((\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND (\"disease\"[MeSH Terms] OR \"disease\"[All Fields])) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19033\n",
      "AR00 search of pubmed found 19033 ids of which 19033 are new\n",
      "Arousal search omit n ids: 0\n",
      "Arousal ids: 19033.\n",
      "\n",
      "psyc search omit n ids: 19033.\n",
      "249889\n",
      "Removed this many ids: 12206\n",
      "psych search of pubmed found 249889 ids of which 237683 are new\n",
      "psyc specific ids: 237683.\n",
      "\n",
      "disease search omit n ids: 256716.\n",
      "579517\n",
      "Removed this many ids: 38950\n",
      "disease search of pubmed found 579517 ids of which 540567 are new\n",
      "disease specific ids: 540567.\n"
     ]
    }
   ],
   "source": [
    "AR00_ids = search_and_summarize(search_name='AR00', query=AR00)\n",
    "omit_ids = None\n",
    "print('Arousal search omit n ids: 0')\n",
    "print('Arousal ids: {}.'.format(len(AR00_ids)))\n",
    "\n",
    "print()\n",
    "omit_ids = list(AR00_ids)\n",
    "print('psyc search omit n ids: {}.'.format(len(omit_ids)))\n",
    "psyc_ids = search_and_summarize(search_name='psych', query=psych, omit_ids=omit_ids)\n",
    "print('psyc specific ids: {}.'.format(len(psyc_ids)))\n",
    "\n",
    "print()\n",
    "omit_ids.extend(psyc_ids)\n",
    "print('disease search omit n ids: {}.'.format(len(omit_ids)))\n",
    "diss_ids = search_and_summarize(search_name='disease', query=disease, omit_ids=omit_ids)\n",
    "print('disease specific ids: {}.'.format(len(diss_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10385\n",
      "auditory_perception search of pubmed found 10385 ids of which 10385 are new\n",
      "auditory perception ids: 10385.\n"
     ]
    }
   ],
   "source": [
    "AP00_ids = search_and_summarize(search_name='auditory_perception', query=AP00)\n",
    "print('auditory perception ids: {}.'.format(len(AP00_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save random samples of pmids to lists and corresponding abstracts to medic database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1000)\n",
    "AR00_1000 = random.sample(AR00_ids, 1000)\n",
    "AP00_1000 = random.sample(AP00_ids, 1000)\n",
    "psyc_1000 = random.sample(psyc_ids, 1000)\n",
    "diss_1000 = random.sample(diss_ids, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./AR00_1000_ids', 'wb') as f:\n",
    "    for item in AR00_1000:\n",
    "        f.write(item + '\\n')\n",
    "\n",
    "with open('./AP00_1000_ids', 'wb') as f:\n",
    "    for item in AP00_1000:\n",
    "        f.write(item + '\\n')\n",
    "\n",
    "with open('./psyc_1000_ids', 'wb') as f:\n",
    "    for item in psyc_1000:\n",
    "        f.write(item + '\\n')\n",
    "\n",
    "with open('./diss_1000_ids', 'wb') as f:\n",
    "    for item in diss_1000:\n",
    "        f.write(item + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Later, we desired additional batches of a couple terms\n",
    "#### More Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "AR00_1200_batch2 = random.sample(AR00_ids, 1200) # we'll trim this to unique new Arousal later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./AR00_1200_batch2_ids', 'wb') as f:\n",
    "    for item in AR00_1200_batch2:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Auditory Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "AP00_1400_batch2 = random.sample(AP00_ids, 1400) # we'll trim this to unique new Arousal later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./AP00_1400_batch2_ids', 'wb') as f:\n",
    "    for item in AP00_1400_batch2:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull asbtracts into a database using Python medic package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp\n",
      "    3359\n"
     ]
    }
   ],
   "source": [
    "%cd tasks/task_data_temp/\n",
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l\n",
    "!medic update --pmid-lists ./AP00_1000_ids 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4337\r\n"
     ]
    }
   ],
   "source": [
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l\n",
    "!medic update --pmid-lists ./AR00_1000_ids 2> /dev/null\n",
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l\n",
    "!medic update --pmid-lists ./AP00_1000_ids 2> /dev/null\n",
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l\n",
    "!medic update --pmid-lists ./psyc_1000_ids 2> /dev/null\n",
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l\n",
    "!medic update --pmid-lists ./diss_1000_ids 2> /dev/null\n",
    "!medic --format tsv write ALL 2> /dev/null | cut -f1 | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!medic --format tsv write --pmid-lists ./diss_1000_ids 2> /dev/null | cut -f1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to medic database the additional batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!medic update --pmid-lists ./AR00_1200_batch2_ids 2> /dev/null\n",
    "!medic update --pmid-lists ./AP00_1400_batch2_ids 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate overlap between sets 1 and the additonal batches to get uniquely new sets for the additional batches\n",
    "Note, permanent location for good lists ../task_data_pmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(len(ar1))\n",
    "# print(len(ar2))\n",
    "# len(set(ar2).intersection(ar1))\n",
    "# uniq_ar2 = [a for a in ar2 if not a in ar1]\n",
    "# print(len(uniq_ar2))\n",
    "# with open('../task_data_pmids/AR00_1000_batch2_ids', 'wb') as f:\n",
    "#     for item in uniq_ar2[0:1000]:\n",
    "#         f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_1000(list1, list2):\n",
    "    \"\"\"Returns unique list of 1000 elements in list1 that are not in list2.\n",
    "    \n",
    "    Presumes at least 1000 items in list1.\n",
    "    \n",
    "    Preserves ordering in list1.\n",
    "    \"\"\"\n",
    "    uniq_list1 = [item for item in list1 if not item in list2]\n",
    "    print('Found {} items unique to list1 from {} total items in list1 and {} total items in list2'.format(len(uniq_list1), len(list1), len(list2)))\n",
    "    if len(uniq_list1) > 1000:\n",
    "        uniq_list1 = uniq_list1[0:1000]\n",
    "    print('Returning {} items from list1'.format(len(uniq_list1)))\n",
    "    return(uniq_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce additional arousal to 1000 unique new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ar1 = !medic --format tsv write --pmid-lists ../task_data_pmids/AR00_1000_ids 2> /dev/null | cut -f1 \n",
    "ar2 = !medic --format tsv write --pmid-lists ./AR00_1200_batch2_ids 2> /dev/null | cut -f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../task_data_pmids/AR00_1000_batch2_ids', 'wb') as f:\n",
    "    for item in uniq_ar2[0:1000]:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reduce additional auditory perception to 1000 unique new terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap1 = !medic --format tsv write --pmid-lists ../task_data_pmids/AP00_1000_ids 2> /dev/null | cut -f1 \n",
    "ap2 = !medic --format tsv write --pmid-lists ./AP00_1400_batch2_ids 2> /dev/null | cut -f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1257 items unique to list1 from 1400 total items in list1 and 1000 total items in list2\n",
      "Returning 1000 items from list1\n"
     ]
    }
   ],
   "source": [
    "uniq_ap2 =  unique_1000(ap2, ap1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../task_data_pmids/AP00_1000_batch2_ids', 'wb') as f:\n",
    "    for item in uniq_ap2[0:1000]:\n",
    "        f.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices: Description of pubmed central resources\n",
    "\n",
    "## A.0 generally pubmed portion to psychology and psychiatry\n",
    "contrast search of pubmed in most recent 5 years human vs. (psychology or psychiatry)\n",
    "\n",
    "Last 5 years, with abstract:\n",
    "\n",
    "- human:\n",
    "  - (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "  - 2267867\n",
    "- psychology or psychiatry:\n",
    "  - (\"psychology\"[Subheading] OR \"psychology\"[All Fields] OR \"psychology\"[MeSH Terms]) OR (\"psychiatry\"[MeSH Terms] OR \"psychiatry\"[All Fields]) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "  - 318188\n",
    "- human AND (psychology or psychiatry)\n",
    "  - (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND ((\"psychology\"[Subheading] OR \"psychology\"[All Fields] OR \"psychology\"[MeSH Terms]) OR (\"psychiatry\"[MeSH Terms] OR \"psychiatry\"[All Fields])) AND (hasabstract[text] AND \"2011/01/31\"[PDat] : \"2016/01/29\"[PDat])\n",
    "  - 249889\n",
    "\n",
    "Approx 11% of human pubmed literature is human psych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1 pubmed resources for programmatic retrieval\n",
    "\n",
    "There are official services useful for article retrieval from pubmed central.\n",
    "\n",
    "### pubmed central programmatic access\n",
    "\n",
    "Note directions at pubmed central on programmatic access.\n",
    "\n",
    "- http://www.ncbi.nlm.nih.gov/pmc/oai\n",
    "- http://www.ncbi.nlm.nih.gov/pmc/tools/oa-service/\n",
    "\n",
    "base urls for retrieval:  \n",
    "- http://www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi\n",
    "- http://www.ncbi.nlm.nih.gov/pmc/utils/oa/oa.fcgi\n",
    "\n",
    "### pubmed listings of open access articles available as text or pdf\n",
    "\n",
    "#### Useful Entrez terms\n",
    "\n",
    "    \"open access\"[filter] - finds PMC articles that are in the OA subset\n",
    "    \"has pdf\"[filter] - finds all PMC articles that have PDF files (including those not in the OA subset)\n",
    "    \"oa full text xml\"[filter] - finds those OA subset articles that have XML\n",
    "\n",
    "#### ftp service (can get pdf along with article XML, or only XML).\n",
    " - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/\n",
    " - (directions) http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/\n",
    " - http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/#Finding_Data\n",
    " - Set TCP FTP client as 32 Mb\n",
    "\n",
    "#### Associating pubmed id to pubmed central id (PMID to PMCID).\n",
    "- ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/PMC-ids.csv.gz\n",
    "- http://www.ncbi.nlm.nih.gov/pmc/tools/id-converter-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2 Description of pubmed vs. pubmed central corpuses and available full text.\n",
    "\n",
    "These are kept quite up to date, so exact counts will vary.\n",
    "\n",
    "The point is to show a few variations on our searches as it relates to the pubmed or pubmed central literature in general.\n",
    "\n",
    "#### pubmed\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND \"loattrfree full text\"[sb]\n",
    "- pubmed search (n=2973711):\n",
    "\n",
    "\n",
    "#### pubmed central searches, counts of resutls.\n",
    "\n",
    "pubmedcentral search:\n",
    "- These all have free articles.\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human[All Fields])\n",
    "- n = 1753712\n",
    "\n",
    "pubmedcentral search limit to free full text:\n",
    "- These all have full text (but not necessarily *free* full text?)\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND \"free full text\"[Filter]\n",
    "- n = 2396446\n",
    "\n",
    "pubmedcentral search 'open access':\n",
    "- Distinguished from 'full text xml' because not all are free text xml?\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND \"open access\"[Filter]\n",
    "- n = 803601\n",
    "\n",
    "**pubmedcentral open access and full text:** \n",
    "- **(DECIDED THIS IS OUR DESIRED SEARCH SPACE)**\n",
    "- These all have free articles AND the full text is retrievable by xml.\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields] OR \"human\"[All Fields]) AND \"open access\"[Filter] AND \"oa full text xml\"Filter\n",
    "- n = 763976\n",
    "\n",
    "pubmedcentral open access and full text but **suboptimal** (forgetting to include 'human' singular:\n",
    "- lose about 1/3 of terms.\n",
    "- (\"humans\"[MeSH Terms] OR \"humans\"[All Fields]) AND \"oa full text xml\"[Filter]\n",
    "- n = 504974\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3 Description of pubmed central id list mappings as fiels.\n",
    "Note on this conversion list:\n",
    "- pmc are unique\n",
    "- a few pmc map to multiple pmid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/data/pubmed_central_open_access\n",
      "Journal Title,ISSN,eISSN,Year,Volume,Issue,Page,DOI,PMCID,PMID,Manuscript Id,Release Date\r",
      "\r\n",
      "Breast Cancer Res,1465-5411,1465-542X,2000,3,1,55,,PMC13900,11250746,,live\r",
      "\r\n",
      "Breast Cancer Res,1465-5411,1465-542X,2000,3,1,61,,PMC13901,11250747,,live\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ccarey/Documents/Projects/NAMI/rdoc\n",
    "# !pwd\n",
    "# !mkdir -p ./data/pubmed_central_open_access\n",
    "%cd ./data/pubmed_central_open_access\n",
    "# !wget ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/PMC-ids.csv.gz\n",
    "!zgrep . PMC-ids.csv.gz | head -3\n",
    "\n",
    "# # R\n",
    "# t <- read.csv('PMC-ids.csv.gz')\n",
    "# > nrow(t)\n",
    "# [1] 3877841\n",
    "# > length(unique(t$PMCID))\n",
    "# [1] 3877841\n",
    "# > length(unique(t$PMID))\n",
    "# [1] 3373788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4 Description full corpuses by pubmed central ftp\n",
    "\n",
    "### Maybe more useful (can validate pmid etc.)\n",
    "\n",
    "Full text extracted either from the xml, or if article only available as pdf, then pmc has extracted the open access text from the pdf.\n",
    "\n",
    ".nxml format, has pmc etc ids. Abstracts and text include lots of markup. figures by href off of base url?\n",
    "\n",
    "    <article-id pub-id-type=\"pmid\">22558545</article-id>\n",
    "    <article-id pub-id-type=\"pmc\">3339583</article-id>\n",
    "\n",
    "full XML, inlcudes pdf and images if relevant (2-6 Gb):\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.A-B.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.C-H.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.I-N.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.O-Z.tar.gz\n",
    "\n",
    "### Maybe easier for text analysis.\n",
    "\n",
    "The extracted full text is not as useful because they do not include the metadata for pubmed id etc. that we could get elsewhere.\n",
    "\n",
    "full extracted text archive files (2-6Gb) \n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.txt.0-9A-B.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.txt.C-H.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.txt.I-N.tar.gz\n",
    "    - ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/articles.txt.O-Z.tar.gz\n",
    "\n",
    "Example article:\n",
    "- articles.txt.0-9A-B/Breast_Cancer_Res/Breast_Cancer_Res_2000_Dec_17_2\\(1\\)_15-21.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID mappings again, but with useful folder location within online or downloaded corpus.\n",
    "Column 1 refers to ftp archive folder location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/data/pubmed_central_open_access\n",
      "2016-01-20 11:27:32\n",
      "08/e0/Breast_Cancer_Res_2001_Nov_2_3(1)_55-60.tar.gz\tBreast Cancer Res. 2001 Nov 2; 3(1):55-60\tPMC13900\tPMID:11250746\n",
      "b0/ac/Breast_Cancer_Res_2001_Nov_9_3(1)_61-65.tar.gz\tBreast Cancer Res. 2001 Nov 9; 3(1):61-65\tPMC13901\tPMID:11250747\n",
      "2016-01-20 11:27:32\n",
      "08/e0/BCR-3-1-055.PMC13900.pdf\tBreast Cancer Res. 2001 Nov 2; 3(1):55-60\tPMC13900\tPMID:11250746\n",
      "b0/ac/BCR-3-1-061.PMC13901.pdf\tBreast Cancer Res. 2001 Nov 9; 3(1):61-65\tPMC13901\tPMID:11250747\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ccarey/Documents/Projects/NAMI/rdoc/data/pubmed_central_open_access\n",
    "# !wget ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/file_list.txt\n",
    "# !wget ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/file_list.pdf.txt\n",
    "!head -3 file_list.txt\n",
    "# !zgrep -c . file_list.txt # 1202748\n",
    "!head -3 file_list.pdf.txt\n",
    "# !zgrep -c . file_list.pdf.txt # 1119897"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A.5 MESH\n",
    "https://www.nlm.nih.gov/bsd/disted/meshtutorial/meshtreestructures/\n",
    "\n",
    "MESH Subheadings under psychology and psychiatry\n",
    "https://www.nlm.nih.gov/mesh/2016/mesh_browser/MeSHtree.F.html#link_id\n",
    "Go back to MeSH Tree Psychiatry and Psychology [F]\n",
    "\n",
    "    Behavior and Behavior Mechanisms [F01]  +\n",
    "    Psychological Phenomena and Processes [F02]  +\n",
    "    Mental Disorders [F03]  +\n",
    "    Behavioral Disciplines and Activities [F04]  + \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A.6 Misc resources and notes\n",
    "\n",
    "### Programmatic OAI noted to not give MESH nor author affiliation\n",
    "http://blog.humaneguitarist.org/2012/05/27/awesome-sauce-augmenting-pubmed-centrals-oai-response/\n",
    "\n",
    "### To get MESH, blogger noted xml from efetch does it.\n",
    "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=12654674&retmode=xml\n",
    "\n",
    "Note, when in pubmed, if we unfold Publication Types, MESH Terms, Substances\n",
    "\n",
    "XML has\n",
    "- MeSH Terms : MeshHeadingList\n",
    "- Substances : ChemicalList\n",
    "\n",
    "Do we know that extended mesh concepts are included?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.7 MESH from python medic database using python medic package\n",
    "\n",
    "To get MESH from medic, medic --format full and select MH rows.\n",
    "\n",
    "Note '*' character should denote major topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "    \n",
    "medic write --format full 21050743 | grep '^PMID\\|^MH'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PMID- 21050743\n",
    "MH  - Animals\n",
    "MH  - Attention/*physiology\n",
    "MH  - Humans\n",
    "MH  - Neurons/physiology\n",
    "MH  - Parietal Lobe/*physiology\n",
    "MH  - Photic Stimulation/methods\n",
    "MH  - Psychomotor Performance/*physiology\n",
    "MH  - Signal Transduction/physiology\n",
    "MH  - Space Perception/*physiology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
