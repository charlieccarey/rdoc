{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add bags of words from additional arousal and non-arousal datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Start postgres if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and start to populate directory for deepdive arousal app.\n",
    "We'll store our configuration information within this directory.\n",
    "\n",
    "We'll store our raw sentences and features for filling tables under the input directory.\n",
    "\n",
    "But note we are starting with some processed files in input. If we had needed to process files to get there, we would have an ./input/input.sh script which would be run by initdb (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/arousal2\n"
     ]
    }
   ],
   "source": [
    "wkdir = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/arousal2'\n",
    "%cd $wkdir\n",
    "!echo postgresql://localhost/deepdive_arousal2 > ./db.url\n",
    "%mkdir ./input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create database schema in the app directory"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# schema.sql contents.\n",
    "DROP TABLE IF EXISTS _raw_sentences CASCADE;\n",
    "CREATE TABLE _raw_sentences (\n",
    "    sentence_id TEXT,\n",
    "    sentence TEXT,\n",
    "    terms TEXT\n",
    "    );\n",
    "\n",
    "DROP TABLE IF EXISTS _annotated_sentences CASCADE;\n",
    "CREATE TABLE _annotated_sentences(\n",
    "  sentence_id text,\n",
    "  words TEXT[],\n",
    "  has_term TEXT,\n",
    "  id bigint   -- reserved for DeepDive\n",
    "  );\n",
    "\n",
    "DROP TABLE IF EXISTS _extracted_features CASCADE;\n",
    "  CREATE TABLE _extracted_features (\n",
    "  sentence_id TEXT,\n",
    "  feature TEXT\n",
    "  );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### populate the input directory with raw sentences and feature extracted sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the annotations for Arousal topic as annotated by Mark.\n",
    "\n",
    "    See 2_spacy_parse_annotations notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we had cleaned our sentences of all empty lines and we had already obtained lemmas for each sentence.\n",
    "\n",
    "Creating raw_sentences from our input files.\n",
    "- fill raw_sentences with sentences.\n",
    "\n",
    "Creating annotated_sentences from our bags of lemmas.\n",
    "\n",
    "Notes:\n",
    "- The '{' delimiter for psql arrays.\n",
    "- Input bags of lemmas were previously cleaned of quote marks and commas so as not to confuse postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 166 FALSE\r\n",
      " 201 TRUE\r\n"
     ]
    }
   ],
   "source": [
    "pos_sent = '/Users/ccarey/Documents/Projects/NAMI/rdoc/results/annotations_processed/AR_mk_pos'\n",
    "pos_bol = '/Users/ccarey/Documents/Projects/NAMI/rdoc/results/annotations_processed/AR_mk_pos_bags-of-lemmas'\n",
    "neg_sent = '/Users/ccarey/Documents/Projects/NAMI/rdoc/results/annotations_processed/AR_mk_tmp_neg'\n",
    "neg_bol = '/Users/ccarey/Documents/Projects/NAMI/rdoc/results/annotations_processed/AR_mk_tmp_neg_bags-of-lemmas'\n",
    "# create raw_sentences from positive and negative sentences.\n",
    "# 1   An example sentence...   TRUE  # + arousal\n",
    "# 222 Another sentence....     FALSE # - arousal\n",
    "!sed 's/$/\\tt/' $pos_sent > ./input/tmp_pos # 201\n",
    "!sed 's/$/\\tf/' $neg_sent > ./input/tmp_neg # 136\n",
    "%cat ./input/tmp* | cat -n | sed 's/^[ ]*//' > ./input/raw_sentences # 367\n",
    "!cut -f3 ./input/raw_sentences | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 166 FALSE\r\n",
      " 201 TRUE\r\n"
     ]
    }
   ],
   "source": [
    "# annotations from the sentences as obtained by NLP\n",
    "# we previously tagged them + / - arousal but want boolean TRUE FALSE\n",
    "!cp $pos_bol ./input/tmp_pos\n",
    "!cp $neg_bol ./input/tmp_neg\n",
    "\n",
    "!sed 's/+arousal/TRUE/' $pos_bol > ./input/tmp_pos # 201\n",
    "!sed 's/-arousal/FALSE/' $neg_bol > ./input/tmp_neg # 136\n",
    "\n",
    "!cat ./input/tmp* | cat -n | sed 's/^[ ]*//' > ./input/annotated_sentences\n",
    "!cut -f3 ./input/annotated_sentences | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Arousal database using deepdive initdb\n",
    "\n",
    "Note, we are skipping the config for now, running deepdive manually. But the file does need to be present.\n",
    "\n",
    "Requires (in the app's directory):\n",
    "- ./db.url : url for postgres database name\n",
    "- ./shema.sql : schema for the db\n",
    "- ./deepdive.conf : configuration which includes feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!touch ./deepdive.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTICE:  table \"_raw_sentences\" does not exist, skipping\r\n",
      "DROP TABLE\r\n",
      "CREATE TABLE\r\n",
      "NOTICE:  table \"_annotated_sentences\" does not exist, skipping\r\n",
      "DROP TABLE\r\n",
      "CREATE TABLE\r\n",
      "NOTICE:  table \"_extracted_features\" does not exist, skipping\r\n",
      "DROP TABLE\r\n",
      "CREATE TABLE\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive initdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             List of relations\r\n",
      " Schema |         Name         | Type  | Owner  |    Size    | Description \r\n",
      "--------+----------------------+-------+--------+------------+-------------\r\n",
      " public | _annotated_sentences | table | ccarey | 8192 bytes | \r\n",
      " public | _extracted_features  | table | ccarey | 8192 bytes | \r\n",
      " public | _raw_sentences       | table | ccarey | 8192 bytes | \r\n",
      "(3 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive sql '\\d+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 367\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./input/raw_sentences | deepdive sql 'COPY _raw_sentences FROM STDIN' # default is TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 367\r\n"
     ]
    }
   ],
   "source": [
    "%cat ./input/annotated_sentences | deepdive sql 'COPY _annotated_sentences FROM STDIN' # default is TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           List of relations\r\n",
      " Schema |         Name         | Type  | Owner  |  Size  | Description \r\n",
      "--------+----------------------+-------+--------+--------+-------------\r\n",
      " public | _annotated_sentences | table | ccarey | 296 kB | \r\n",
      " public | _extracted_features  | table | ccarey | 728 kB | \r\n",
      " public | _raw_sentences       | table | ccarey | 120 kB | \r\n",
      "(3 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive sql '\\d+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " count \n",
      "-------\n",
      "   201\n",
      "(1 row)\n",
      "\n",
      " count \n",
      "-------\n",
      "   166\n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# positive examples\n",
    "!deepdive sql 'SELECT count(*) FROM _annotated_sentences WHERE has_term = True' # or +arousal\n",
    "# negative examples\n",
    "!deepdive sql \"SELECT count(*) FROM _annotated_sentences WHERE has_term = False\" # or - arousal.\n",
    "\n",
    "deepdive sql \"select count(*) from _annotated_sentences where is_true IS TRUE\"\n",
    "deepdive sql \"select count(*) from _annotated_sentences where is_true IS FALSE\"\n",
    "deepdive sql \"select count(*) from _annotated_sentences where is_true IS NULL\"\n",
    "deepdive sql \"select count(*) from _annotated_sentences\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill _extracted_features with the lemmas and bi-lemmas from the annotations.\n",
    "\n",
    "This is like Extractor 2: in the has_spouse example, where they extracting 'mentions'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Think we want all, else add # WHERE has_term = '-arousal' \\\n",
    "\n",
    "# array_to_string simplifies are parsing by removing the braces '{}'\n",
    "cmd=\"\"\"COPY \\\n",
    "(SELECT sentence_id, array_to_string(words, ',') \\\n",
    "FROM _annotated_sentences) \\\n",
    "TO STDOUT WITH NULL AS ''\"\"\"\n",
    "records = !deepdive sql \"$cmd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extracted_features = []\n",
    "for rec in records:\n",
    "    sent_id, lemmas = rec.split('\\t')\n",
    "    lemmas = lemmas.split(',')\n",
    "    for lemma in lemmas:\n",
    "        extracted_features.append('{}\\t{}\\n'.format(sent_id, lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./tmp', 'w') as f:\n",
    "    f.writelines(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPY 15445\r\n"
     ]
    }
   ],
   "source": [
    "!cat './tmp' | deepdive sql 'COPY _extracted_features FROM STDIN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd=\"\"\"SELECT ef.feature \\\n",
    "FROM \\\n",
    "_extracted_features AS ef, \\\n",
    "_annotated_sentences AS ans \\\n",
    "WHERE ef.sentence_id = ans.sentence_id AND ans.has_term = '-arousal' LIMIT 10\"\"\"\n",
    "count_neg_cmd=\"\"\"SELECT count(*) \\\n",
    "FROM \\\n",
    "_extracted_features AS ef, \\\n",
    "_annotated_sentences AS ans \\\n",
    "WHERE ef.sentence_id = ans.sentence_id AND ans.has_term = '-arousal'\"\"\"\n",
    "count_pos_cmd=\"\"\"SELECT count(*) \\\n",
    "FROM \\\n",
    "_extracted_features AS ef, \\\n",
    "_annotated_sentences AS ans \\\n",
    "WHERE ef.sentence_id = ans.sentence_id AND ans.has_term = '+arousal'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  invalid input syntax for type boolean: \"-arousal\"\r\n",
      "LINE 1: ....sentence_id = ans.sentence_id AND ans.has_term = '-arousal'\r\n",
      "                                                             ^\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive sql \"$count_neg_cmd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  invalid input syntax for type boolean: \"+arousal\"\r\n",
      "LINE 1: ....sentence_id = ans.sentence_id AND ans.has_term = '+arousal'\r\n",
      "                                                             ^\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive sql \"$count_pos_cmd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  invalid input syntax for type boolean: \"-arousal\"\r\n",
      "LINE 1: ....sentence_id = ans.sentence_id AND ans.has_term = '-arousal'...\r\n",
      "                                                             ^\r\n"
     ]
    }
   ],
   "source": [
    "!deepdive sql \"$cmd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want boolean column to match examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!deepdive sql 'ALTER TABLE _annotated_sentences ADD COLUMN \"has_term_b\" BOOLEAN DEFAULT FALSE;'\n",
    "!deepdive sql \"UPDATE _annotated_sentences SET has_term_b = (has_term = '+arousal')\" # 367\n",
    "!deepdive sql \"select count(*) from _annotated_sentences where has_term_b = TRUE;\"\n",
    "!deepdive sql \"select count(*) from _annotated_sentences where has_term_b = FALSE;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id | sentence_id \r\n",
      "----+-------------\r\n",
      "  0 | 1\r\n",
      "  1 | 1\r\n",
      "  3 | 1\r\n",
      "  4 | 1\r\n",
      "  6 | 1\r\n",
      "(5 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# cmd=\"\"\"SELECT ef.feature \\\n",
    "# FROM \\\n",
    "# _extracted_features AS ef, \\\n",
    "# _annotated_sentences AS ans \\\n",
    "# WHERE ef.sentence_id = ans.sentence_id AND (ans.has_term) LIMIT 10\"\"\"\n",
    "# !deepdive sql \"$cmd\"\n",
    "\n",
    "# cmd=\"\"\"SELECT s.id AS _annotated_sentences.id,\\\n",
    "# s.has_term AS _annotated_sentences.has_term,\\\n",
    "# f.feature AS feature \\\n",
    "# FROM \\\n",
    "# _annotated_sentences AS s, \\\n",
    "# _extracted_features AS f \\\n",
    "# WHERE \\\n",
    "# (s.sentence_id = f.sentence_id)\"\"\"\n",
    "\n",
    "cmd=\"\"\"SELECT s.id, f.sentence_id \\\n",
    "FROM \\\n",
    "_annotated_sentences AS s, \\\n",
    "_extracted_features AS f \\\n",
    "limit 5\"\"\"\n",
    "!deepdive sql \"$cmd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-a1309c28290b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-a1309c28290b>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    50023  deepdive sql 'ALTER TABLE _annotated_sentences drop has_term'\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(cmd)\n",
    "50023  deepdive sql 'ALTER TABLE _annotated_sentences drop has_term'\n",
    "50024  deepdive sql 'ALTER TABLE _annotated_sentences ADD has_term'\n",
    "50025  deepdive sql 'ALTER TABLE _annotated_sentences ADD column has_term'\n",
    "50026  deepdive sql 'ALTER TABLE _annotated_sentences ADD column has_term;'\n",
    "50027  deepdive sql 'ALTER TABLE _annotated_sentences ADD has_term;'\n",
    "50028  deepdive sql 'ALTER TABLE _annotated_sentences ADD has_term boolean;'\n",
    "50029  deepdive sql 'UPDATE _annotated_sentences SET has_term = IsTrue(has_term_b)'\n",
    "50030  deepdive sql 'UPDATE _annotated_sentences SET has_term = (has_term_b)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running now with a very stripped down config file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "deepdive {\n",
    "\n",
    "    schema.variables {\n",
    "        _annotated_sentences.has_term: Boolean\n",
    "    }\n",
    "    extraction.parallelism: 4\n",
    "\n",
    "    extraction.extractors {\n",
    "\n",
    "    \n",
    "    }\n",
    "    \n",
    "    inference.factors {\n",
    "        IS_ASSOCIATED_TO_RDOC_TERM {\n",
    "            input_query: \"\"\"\n",
    "                SELECT\n",
    "                    s.id AS \"_annotated_sentences.id\",\n",
    "                    s.has_term AS \"_annotated_sentences.has_term\",\n",
    "                    f.feature AS \"feature\"\n",
    "                FROM\n",
    "                    _annotated_sentences AS s,\n",
    "                    _extracted_features AS f\n",
    "                WHERE\n",
    "                    (s.sentence_id = f.sentence_id)\n",
    "                \"\"\"\n",
    "\n",
    "            function: \"IsTrue(_annotated_sentences.has_term)\"\n",
    "            weight: \"?(feature)\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    calibration.holdout_fraction: 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
