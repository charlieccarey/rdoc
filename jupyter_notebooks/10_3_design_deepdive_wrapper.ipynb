{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate labeled input source data for deepdive apps. (and additional sketches of pipeline strategy)\n",
    "Goal is to support multiple rounds of annotation based training and prediction using DeepDive with minimal programming between rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approach to creating our simple deepdive apps based on bag of words.\n",
    "\n",
    "We are mainly interested in step 1.1 listed below in this current notebook.\n",
    "\n",
    "1) Setup input data:\n",
    "  - 1.1 setup input files of sentences with labels\n",
    "    - these serve as source data or a parts list for each specific app.\n",
    "    - raw with labels\n",
    "    - NLP processed or annotated for topic at hand with labels.\n",
    "      - This is where bag of words is performed.\n",
    "  - 1.2 setup app specific combinations of the raw or annotated sentences.\n",
    "    - these will later be copied into our deepdive apps input folder.\n",
    "\n",
    "2) Edit master templates as necessary:\n",
    "  - edit input.sh if necessary (we haven't needed to yet.)\n",
    "\n",
    "3) Copy and modify deepdive templates and input data to create an app.\n",
    "    - cc_setup_deepdive template_source_dir topic app_name num_training num_test\n",
    "    - mkdir\n",
    "    - copy template files\n",
    "    - assign app url\n",
    "    - copy input data files (the sentence or abstract combinations above)\n",
    "\n",
    "4) Run deepdive and our reporting scripts for our app.\n",
    "    - cc_run_and_stats_on_deepdive\n",
    "    - deepdive initdb\n",
    "    - deepdive run\n",
    "    - sql extract confusion matrix based stats\n",
    "    - R graph stats\n",
    "    - sql report top terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General extensions of deepdive app creation\n",
    "3 and 4 conceivably can be looped.\n",
    " - to get validation statistics.\n",
    " - to test results at various levels of subsampling of input data.\n",
    " \n",
    "1 or deepdive .conf from 3 would require editing in order to test other variations of NLP generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------!\n",
    "#\n",
    "# For training data, we have the known 'standards' ('t' or 'f').\n",
    "#\n",
    "# But we also pseudoscore the training data to postgres nulls ('\\N').\n",
    "#\n",
    "# The null pseudoscores are in order to allow us to predict on\n",
    "# our training set because deepdive does not otherwise allow us to \n",
    "# easily view how the training set scored with the exception of the\n",
    "# portion of the training set 'heldout' from training.\n",
    "#\n",
    "#-------------------------------------------------------------------!\n",
    "\n",
    "# auditory = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/batch_05_AP_pmids')\n",
    "# unknown_prob_auditory = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AP00_1000_ids')\n",
    "# disease = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/diss_1000_ids')\n",
    "# psyc = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/psyc_1000_ids') # closer than disease, assume non-overlapping\n",
    "# arousal = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AR00_1000_ids') # closer than psyc, assume non-overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write files for use as input sources for a simple deepdive app based on 't' 'f' labels\n",
    "### Raw sentences (are abstracts extracted from our medic database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start server (required here for medic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bash\n",
    "!pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start # deepdive and medic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bowp.append_raw_sentences('raw_sentences_auditory_perception', auditory, 't')\n",
    "# bowp.append_raw_sentences('raw_sentences_auditory_perception_nulled', auditory, '\\N') # pseudscoring nulls\n",
    "# bowp.append_raw_sentences('raw_sentences_disease', disease, 'f')\n",
    "# bowp.append_raw_sentences('raw_sentences_diseasae_nulled', disease, '\\N') # pseudoscoring nulls\n",
    "# bowp.append_raw_sentences('raw_sentences_psyc', psyc, 'f')\n",
    "# bowp.append_raw_sentences('raw_sentences_psyc_nulled', psyc, '\\N') # pseudoscoring nulls\n",
    "# bowp.append_raw_sentences('raw_sentences_arousal', arousal, 'f')\n",
    "# bowp.append_raw_sentences('raw_sentences_arousal_nulled', arousal, '\\N') # pseudoscoring nulls\n",
    "\n",
    "# bowp.append_raw_sentences('raw_sentences_unknown_auditory_perception', unknown_prob_auditory, '\\N') # prediction set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated sentences (are abstracts from our medic databse and processed as bags of words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute intensive\n",
    "# bowp.append_annotated_sentences('annotated_sentences_auditory_perception', \n",
    "#                                 bowp.get_scored_abstract_bow(auditory, 't'))\n",
    "# bowp.append_annotated_sentences('annotated_sentences_auditory_perception_nulled', \n",
    "#                                 bowp.get_scored_abstract_bow(auditory, '\\N')) # pseudscoring nulls\n",
    "# bowp.append_annotated_sentences('annotated_sentences_disease_false', \n",
    "#                                 bowp.get_scored_abstract_bow(disease, 'f'))\n",
    "# bowp.append_annotated_sentences('annotated_sentences_diseasae_nulled', \n",
    "#                                 bowp.get_scored_abstract_bow(disease, '\\N')) # pseudoscoring nulls\n",
    "# bowp.append_annotated_sentences('annotated_sentences_psyc_false', \n",
    "#                                 bowp.get_scored_abstract_bow(psyc, 'f'))\n",
    "# bowp.append_annotated_sentences('annotated_sentences_psyc_nulled', \n",
    "#                                 bowp.get_scored_abstract_bow(psyc, '\\N')) # pseudoscoring nulls\n",
    "# bowp.append_annotated_sentences('annotated_sentences_arousal_false', \n",
    "#                                 bowp.get_scored_abstract_bow(arousal, 'f'))\n",
    "# bowp.append_annotated_sentences('annotated_sentences_arousal_nulled', \n",
    "#                                 bowp.get_scored_abstract_bow(arousal, '\\N')) # pseudoscoring nulls\n",
    "\n",
    "# bowp.append_annotated_sentences('annotated_sentences_unknown_auditory_perception_nulled',\n",
    "#                                 bowp.get_scored_abstract_bow(unknown_prob_auditory, '\\N')) # prediction set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add raw and annotated sentences for one of our well annotated 'positive' classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arousal_156 = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/batch_04_AR_pmids') # nearly all of these are relevant\n",
    "# bowp.append_raw_sentences('raw_sentences_arousal_156', arousal_156, 't')\n",
    "# bowp.append_raw_sentences('raw_sentences_arousal_156_nulled', arousal_156, '\\N') # pseudscoring nulls\n",
    "# bowp.append_raw_sentences('raw_sentences_arousal_156_false', arousal_156, 'f') # try it as a negative set too.\n",
    "\n",
    "# bowp.append_annotated_sentences('annotated_sentences_arousal_156',\n",
    "#                                 bowp.get_scored_abstract_bow(arousal_156, 't')) # prediction set\n",
    "# bowp.append_annotated_sentences('annotated_sentences_arousal_156_nulled',\n",
    "#                                 bowp.get_scored_abstract_bow(arousal_156, '\\N'))\n",
    "# bowp.append_annotated_sentences('annotated_sentences_arousal_156_false',\n",
    "#                                 bowp.get_scored_abstract_bow(arousal_156, 'f')) # prediction set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each topic create parts of the input data for deepdive.\n",
    "\n",
    "For every topic, fetch sentences and save TSV files that include a column filled with a label.\n",
    "\n",
    "'t', 'f' and '\\N' versions are saved for each topic file.\n",
    "\n",
    "That way, we can mix and match them to obtain various deepdive test / train and or prediction sets.\n",
    "\n",
    "Note the annotated_sentences all derive from raw_sentences and could be processed by an extractor in deepdive instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we also save Null for datasets that will be used as positives?\n",
    "\n",
    "For training data, we have the known 'standards' ('t' or 'f').\n",
    "\n",
    "But we also pseudoscore the training data to postgres nulls ('\\N').\n",
    "\n",
    "The null pseudoscores are in order to allow us to predict on\n",
    "our training set because deepdive does not otherwise allow us to \n",
    "easily view how the training set scored with the exception of the\n",
    "portion of the training set 'heldout' from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/ccarey/Documents/my_scripts/charcar/nlp') # see appendix\n",
    "import bag_of_words_parsing as bowp\n",
    "\n",
    "def get_abstracts(pmid_list_file):\n",
    "    abstracts=!medic --format tsv write --pmid-list {pmid_list_file} 2>/dev/null\n",
    "    return([a.split('\\t', 2) for a in abstracts])\n",
    "\n",
    "def write_abstracts(pmid_list, name, dest_dir, append=False):\n",
    "    '''\n",
    "    writes raw abstracts into SQL acceptable TSV table.\n",
    "    writes annotated abstracts into SQL acceptable TSV table.\n",
    "    \n",
    "    Parameters:\n",
    "        name (str): name of subject to be included in output filename.\n",
    "        pmid_list (str): name of file containing pubmed ids.\n",
    "        \n",
    "    3 different labeled versions of each are created so \n",
    "    they can later be combined with others.\n",
    "    \n",
    "    Labeling supports deepdive apps based on template found in\n",
    "    'templates_deepdive_app_bagofwords'\n",
    "    \n",
    "    The annotated abstracts are bags of words processed by NLP.\n",
    "    \n",
    "    medic database is presumed to already contain records \n",
    "    for the pmids in pmid_list.\n",
    "    '''\n",
    "    labels = {'false':'f', 'true':'t', 'nulled':'\\N'}\n",
    "    raw_fname = os.path.join(dest_dir, 'raw_sentences_' + name)\n",
    "    ann_fname = os.path.join(dest_dir, 'annotated_sentences_' + name)\n",
    "    \n",
    "    abstracts = get_abstracts(pmid_list)\n",
    "    \n",
    "    for k,v in labels.iteritems():\n",
    "        if not append:\n",
    "            try: \n",
    "                os.remove(raw_fname + '_' + k)\n",
    "            except OSError:\n",
    "                pass\n",
    "            try: \n",
    "                os.remove(ann_fname + '_' + k)\n",
    "            except OSError:\n",
    "                pass\n",
    "    # TODO: For efficiency, in bag of words parsing,\n",
    "    # TODO: could just do parsing once, and then apply the labels.\n",
    "    for k,v in labels.iteritems():\n",
    "        bowp.append_raw_sentences(raw_fname + '_' + k, abstracts, v)\n",
    "        bowp.append_annotated_sentences(ann_fname + '_' + k, \n",
    "                                bowp.get_scored_abstract_bow(abstracts, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences: File exists\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences\n"
     ]
    }
   ],
   "source": [
    "%mkdir '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences'\n",
    "%cd  '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the pubmed id lists that we know by manual annotation are probably all positive for topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auditory_146_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/batch_05_AP_pmids'\n",
    "arousal_156_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/batch_04_AR_pmids' # nearly all of these are relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the pubmed id lists that we believe are likely positive for topic due to pubmed search term used.\n",
    "\n",
    "Note, most of these pubmed id lists were initially generated in 8_0_1_fetch_random_human_abstracts.ipynb.\n",
    "\n",
    "When a 2nd set of some were created, they were done such that they were non-overlapping with the first set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disease_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/diss_1000_ids'\n",
    "psyc_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/psyc_1000_ids' # closer than disease, assume non-overlapping\n",
    "arousal_1_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AR00_1000_ids' # closer than psyc, assume non-overlapping\n",
    "auditory_1_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AP00_1000_ids'\n",
    "# 2nd set of 1000 each (note pmid-lists were previously selected to non-overlapping pmids compared to first set.)\n",
    "arousal_2_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AR00_1000_batch2_ids'\n",
    "auditory_2_fname = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_pmids/AP00_1000_batch2_ids'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the labeled sentences or processed sentences for each topic\n",
    "Serves as raw data to be combined into deepdive training, testing and prediction input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will take a while, especially on larger sets.\n",
    "\n",
    "write_abstracts(auditory_146_fname, 'auditory_146', '.', append=False)\n",
    "write_abstracts(arousal_156_fname, 'arousal_156', '.', append=False)\n",
    "\n",
    "write_abstracts(disease_fname, 'disease_1_1000', '.', append=False)\n",
    "write_abstracts(psyc_fname, 'psyc_1_1000', '.', append=False)\n",
    "write_abstracts(auditory_1_fname, 'auditory_1_1000', '.', append=False)\n",
    "write_abstracts(arousal_1_fname, 'arousal_1_1000', '.', append=False)\n",
    "\n",
    "write_abstracts(auditory_2_fname, 'auditory_2_1000', '.', append=False)\n",
    "write_abstracts(arousal_2_fname, 'arousal_2_1000', '.', append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## edit resulting files to remove 'empty' abstracts\n",
    "These records without sentence or abstract data would accidentally crash our deepdive apps (probably due to our python script in our deepdive user defined functino (udf) folder). \n",
    "\n",
    "Not sure why these specific pubmed ids contained these errors and not others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences\n",
      "./annotated_sentences_arousal_156_false:16:21626350\t{}\tf\t\\N\n",
      "./annotated_sentences_arousal_156_false:39:25325584\t{}\tf\t\\N\n",
      "./annotated_sentences_arousal_156_nulled:16:21626350\t{}\t\\N\t\\N\n",
      "./annotated_sentences_arousal_156_nulled:39:25325584\t{}\t\\N\t\\N\n",
      "./annotated_sentences_arousal_156_true:16:21626350\t{}\tt\t\\N\n",
      "./annotated_sentences_arousal_156_true:39:25325584\t{}\tt\t\\N\n",
      "./raw_sentences_arousal_156_false:16:21626350\t\tf\t\\N\n",
      "./raw_sentences_arousal_156_false:39:25325584\t\tf\t\\N\n",
      "./raw_sentences_arousal_156_nulled:16:21626350\t\t\\N\t\\N\n",
      "./raw_sentences_arousal_156_nulled:39:25325584\t\t\\N\t\\N\n",
      "./raw_sentences_arousal_156_true:16:21626350\t\tt\t\\N\n",
      "./raw_sentences_arousal_156_true:39:25325584\t\tt\t\\N\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!grep -n '\\t\\t\\|{}' ./[ar]* # line numbering so we know we aren't throwing other records out of sync across files.\n",
    "# one of files with the error\n",
    "# !grep -n '21626350\\|25325584' ./* | cut -d ':' -f1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing the bad lines (and backing up original)\n",
    "# note sed -i is gnu sed.\n",
    "!sed -i.bak '/21626350\\t/d;/25325584\\t/d' ./[ar]*arousal_156*\n",
    "# testing success\n",
    "# !grep -n '\\t\\t\\|{}' ./* # should only be backups\n",
    "# !rm ./*.bak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary, resulting number of labeled 'sentences' by label type.\n",
    "- usually abstracts rather than sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     154 ./annotated_sentences_arousal_156_false\r\n",
      "    1000 ./annotated_sentences_arousal_1_1000_false\r\n",
      "    1000 ./annotated_sentences_arousal_2_1000_false\r\n",
      "     146 ./annotated_sentences_auditory_146_false\r\n",
      "    1000 ./annotated_sentences_auditory_1_1000_false\r\n",
      "    1000 ./annotated_sentences_auditory_2_1000_false\r\n",
      "    1000 ./annotated_sentences_disease_1_1000_false\r\n",
      "    1000 ./annotated_sentences_psyc_1_1000_false\r\n",
      "     154 ./raw_sentences_arousal_156_false\r\n",
      "    1000 ./raw_sentences_arousal_1_1000_false\r\n",
      "    1000 ./raw_sentences_arousal_2_1000_false\r\n",
      "     146 ./raw_sentences_auditory_146_false\r\n",
      "    1000 ./raw_sentences_auditory_1_1000_false\r\n",
      "    1000 ./raw_sentences_auditory_2_1000_false\r\n",
      "    1000 ./raw_sentences_disease_1_1000_false\r\n",
      "    1000 ./raw_sentences_psyc_1_1000_false\r\n"
     ]
    }
   ],
   "source": [
    "!find . -type f -name \"*false\" | parallel wc -l {} | sort -k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     154 ./annotated_sentences_arousal_156_nulled\r\n",
      "    1000 ./annotated_sentences_arousal_1_1000_nulled\r\n",
      "    1000 ./annotated_sentences_arousal_2_1000_nulled\r\n",
      "     146 ./annotated_sentences_auditory_146_nulled\r\n",
      "    1000 ./annotated_sentences_auditory_1_1000_nulled\r\n",
      "    1000 ./annotated_sentences_auditory_2_1000_nulled\r\n",
      "    1000 ./annotated_sentences_disease_1_1000_nulled\r\n",
      "    1000 ./annotated_sentences_psyc_1_1000_nulled\r\n",
      "     154 ./raw_sentences_arousal_156_nulled\r\n",
      "    1000 ./raw_sentences_arousal_1_1000_nulled\r\n",
      "    1000 ./raw_sentences_arousal_2_1000_nulled\r\n",
      "     146 ./raw_sentences_auditory_146_nulled\r\n",
      "    1000 ./raw_sentences_auditory_1_1000_nulled\r\n",
      "    1000 ./raw_sentences_auditory_2_1000_nulled\r\n",
      "    1000 ./raw_sentences_disease_1_1000_nulled\r\n",
      "    1000 ./raw_sentences_psyc_1_1000_nulled\r\n"
     ]
    }
   ],
   "source": [
    "!find . -type f -name \"*nulled\"| parallel wc -l {} | sort -k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0 ./.DS_Store\r\n",
      "     154 ./annotated_sentences_arousal_156_true\r\n",
      "    1000 ./annotated_sentences_arousal_1_1000_true\r\n",
      "    1000 ./annotated_sentences_arousal_2_1000_true\r\n",
      "     146 ./annotated_sentences_auditory_146_true\r\n",
      "    1000 ./annotated_sentences_auditory_1_1000_true\r\n",
      "    1000 ./annotated_sentences_auditory_2_1000_true\r\n",
      "    1000 ./annotated_sentences_disease_1_1000_true\r\n",
      "    1000 ./annotated_sentences_psyc_1_1000_true\r\n",
      "     154 ./raw_sentences_arousal_156_true\r\n",
      "    1000 ./raw_sentences_arousal_1_1000_true\r\n",
      "    1000 ./raw_sentences_arousal_2_1000_true\r\n",
      "     146 ./raw_sentences_auditory_146_true\r\n",
      "    1000 ./raw_sentences_auditory_1_1000_true\r\n",
      "    1000 ./raw_sentences_auditory_2_1000_true\r\n",
      "    1000 ./raw_sentences_disease_1_1000_true\r\n",
      "    1000 ./raw_sentences_psyc_1_1000_true\r\n"
     ]
    }
   ],
   "source": [
    "!find . -type f ! \\( -name \"*false\" -o -name \"*nulled\" \\) | parallel wc -l {} | sort -k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unfinished code from hereon.\n",
    "## These are sketches towards wrapping deepdive app creation.\n",
    "## See notebook 11 and later for examples of deepdive apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_lines_file(fname):\n",
    "    n_lines = 0\n",
    "    with open(fname, 'r') as f:\n",
    "        n_lines = sum(1 for _ in f)\n",
    "    return(n_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example, apps with different sample sizes\n",
    " - for auditory perception as positive (per annotators recommendation) \n",
    " - disease as negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_sentences_dir = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_sentences/all_sentences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_n_lines_file(os.path.join(all_sentences_dir, 'annotated_sentences_auditory_perception'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Setup each of the sampling sizes\n",
    "\n",
    "range(25, max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per single app or sampling regimen copy templates and setup single app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "templates='/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/templates_deepdive_app_bagofwords'\n",
    "dd_app_dir = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/'\n",
    "# training = '/Users/ccarey/Documents/Projects/NAMI/rdoc/.../some file of training sentences'\n",
    "# prediction = '/Users/ccarey/Documents/Projects/NAMI/rdoc/.../some file of prediction sentences'\n",
    "\n",
    "os.chdir(dd_app_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# example of input/init.sh\n",
    "# note APP_HOME = app directory.\n",
    "deepdive sql \"DELETE FROM _raw_sentences\"\n",
    "deepdive sql \"COPY _raw_sentences FROM STDIN\" < ${APP_HOME}\"/input/raw_sentences\"\n",
    "deepdive sql \"DELETE FROM _annotated_sentences\"\n",
    "deepdive sql \"COPY _annotated_sentences FROM STDIN\" < ${APP_HOME}\"/input/annotated_sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cc_setup_deepdive(template_source_dir, fname_train, fname_predict, topic='current_topic', app_name='current_app'):\n",
    "    '''\n",
    "    template_source_dir : directory containing deepdive.conf, folders, and input/init.sh\n",
    "    train_fname : file containing data for training, 1 sample per line\n",
    "    predict_fname : file containing data for prediction, 1 sample per line\n",
    "    '''\n",
    "    app = topic + '_' + app_name + '__' + fname_train + '__' + fname_train + '_' + fname_predict\n",
    "    shutil.copytree(template_source_dir, app)\n",
    "    with open(os.path.join(app_name + 'db.url'), 'w') as f:\n",
    "        f.write('postgresql://localhost/' + app + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range[]\n",
    "app = 'test_app'\n",
    "cc_setup_deepdive(template_source_dir=templates,\n",
    "                  topic='a_topic',\n",
    "                  app_name=app_name,\n",
    "                  fname_train='training',\n",
    "                  fname_predict='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc_setup_deepdive(template_source_dir=templates,\n",
    "                  topic='a_topic',\n",
    "                  app_name=app_name,\n",
    "                  fname_train=training,\n",
    "                  fname_predict=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices\n",
    "\n",
    "## A.1 Medic interaction\n",
    "Python's medic module is being used to store abstract information.\n",
    "\n",
    "Tables of interest:\n",
    "- descriptors: Probably MH Medline headings.\n",
    "- qualifiers: Probably MH additional qualifiers, like major topic.\n",
    "- some abstracts seem to be generated from the *content* field of the 'sections' table.\n",
    "- abstract field is entirely copyright.\n",
    "- databases table gives access out to other databases, not necessarily all. (see pubmed on 25882325 for example.)\n",
    "- chemicals table is content of the 'substances' doing a pubmed search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use postgres array_agg() to concatenate the content to get back a single abstract when that content is spread across multiple rows in the sections table.\n",
    "\n",
    "(Assuming that only the abstract is in the content)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "select array_to_string(array_agg(content), ' ') as abstract from sections where pmid = 22735387;\n",
    "\n",
    "select  * from databases where pmid = 25882325;\n",
    "\n",
    "25882325 | ClinicalTrials.gov | NCT01396421"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "medline=# \\d+\n",
    "                              List of relations\n",
    " Schema |        Name         |   Type   | Owner  |    Size    | Description\n",
    "--------+---------------------+----------+--------+------------+-------------\n",
    " public | abstracts           | table    | ccarey | 352 kB     |\n",
    " public | authors             | table    | ccarey | 1392 kB    |\n",
    " public | authors_pos_seq     | sequence | ccarey | 8192 bytes |\n",
    " public | chemicals           | table    | ccarey | 248 kB     |\n",
    " public | chemicals_idx_seq   | sequence | ccarey | 8192 bytes |\n",
    " public | citations           | table    | ccarey | 944 kB     |\n",
    " public | databases           | table    | ccarey | 64 kB      |\n",
    " public | descriptors         | table    | ccarey | 3464 kB    |\n",
    " public | descriptors_num_seq | sequence | ccarey | 8192 bytes |\n",
    " public | identifiers         | table    | ccarey | 832 kB     |\n",
    " public | keywords            | table    | ccarey | 384 kB     |\n",
    " public | keywords_cnt_seq    | sequence | ccarey | 8192 bytes |\n",
    " public | publication_types   | table    | ccarey | 632 kB     |\n",
    " public | qualifiers          | table    | ccarey | 1472 kB    |\n",
    " public | qualifiers_sub_seq  | sequence | ccarey | 8192 bytes |\n",
    " public | sections            | table    | ccarey | 7048 kB    |\n",
    " public | sections_seq_seq    | sequence | ccarey | 8192 bytes |\n",
    " \n",
    "medline=# select * from qualifiers where pmid = '22735387';\n",
    "   pmid   | num | sub | major |        name\n",
    "----------+-----+-----+-------+--------------------\n",
    " 22735387 |   2 |   1 | f     | chemically induced\n",
    " 22735387 |   3 |   1 | f     | drug effects\n",
    " 22735387 |   4 |   1 | f     | blood\n",
    " 22735387 |   8 |   1 | t     | toxicity\n",
    " 22735387 |  11 |   1 | t     | metabolism\n",
    " 22735387 |  13 |   1 | t     | toxicity\n",
    " 22735387 |  15 |   1 | f     | drug effects\n",
    "(7 rows)\n",
    "\n",
    "medline=# select * from descriptors where pmid = '22735387';\n",
    "   pmid   | num | major |                  name\n",
    "----------+-----+-------+-----------------------------------------\n",
    " 22735387 |   1 | f     | Adolescent\n",
    " 22735387 |   2 | f     | Anemia\n",
    " 22735387 |   3 | f     | Auditory Perception\n",
    " 22735387 |   4 | f     | Biomarkers\n",
    " 22735387 |   5 | f     | Child\n",
    " 22735387 |   6 | f     | Child, Preschool\n",
    " 22735387 |   7 | t     | Environmental Exposure\n",
    " 22735387 |   8 | f     | Environmental Pollutants\n",
    " 22735387 |   9 | t     | Evoked Potentials, Auditory, Brain Stem\n",
    " 22735387 |  10 | f     | Female\n",
    " 22735387 |  11 | f     | Hemoglobins\n",
    " 22735387 |  12 | f     | Humans\n",
    " 22735387 |  13 | f     | Lead\n",
    " 22735387 |  14 | f     | Male\n",
    " 22735387 |  15 | f     | Reaction Time\n",
    " 22735387 |  16 | f     | Statistics, Nonparametric\n",
    "(16 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2 NLP parsing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/usr/env/bin python\n",
    "# file bag_of_words_parsing.py\n",
    "import io\n",
    "import codecs\n",
    "from spacy.en import English\n",
    "nlp = English(parser=True, tagger=True) # so we can sentence parse\n",
    "\n",
    "def spacy_lemma_gt_len(text, length=2):\n",
    "    '''Create bag of unique lemmas, requiring lemma length > length\n",
    "    \n",
    "    Note: setting length to 1 may mess up our postgres arrays as we would\n",
    "    get commas here, unless we were to quote everything.\n",
    "    '''\n",
    "    tokens = []\n",
    "    #doc = nlp(text.decode('utf8')) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    parsed_data = nlp(text) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    for token in parsed_data:\n",
    "        if len(token.lemma_) > length:\n",
    "            tokens.append(token.lemma_.lower())\n",
    "    return(list(set(tokens)))\n",
    "\n",
    "# def remove_stop_words():\n",
    "#     pass\n",
    "\n",
    "def spacy_lemma_biwords_gt_len(text, length=3):\n",
    "    '''Create bag of unique bi-lemmas, requiring lemma length > length\n",
    "    \n",
    "    We are crudely eliminating any bi-lemmas that have commas in them to save us in loading postgres arrays.\n",
    "    '''\n",
    "    biwords = []\n",
    "    parsed_data = nlp(text)\n",
    "    skip_chars = [',', '\"', \"'\"]\n",
    "    for i in range(1, len(parsed_data) - 1):\n",
    "        skip = False\n",
    "        biword = u'{} {}'.format(parsed_data[i].lemma_.lower(), parsed_data[i+1].lemma_.lower())\n",
    "        if (parsed_data[i].lemma_ in skip_chars or parsed_data[i+1].lemma_ in skip_chars):\n",
    "            skip = True\n",
    "        if len(biword) > length and not skip:\n",
    "            biwords.append(biword)\n",
    "    return(list(set(biwords)))\n",
    "\n",
    "def get_scored_abstract_bow(abstracts, score):\n",
    "    '''Return annotated bag of words.\n",
    "     my_id   sentences   [tf]    \\N\n",
    "     - score (postgres boolean) :  t f \\N\n",
    "     - column 3, true, false, null.\n",
    "     - column 4 null id for deepdive's use.\n",
    "     - {{}} is to wrap list as postgres array.\n",
    "    '''\n",
    "    results = []\n",
    "    for a in abstracts:\n",
    "        # bow = spacy_lemma_gt_len(a[2].decode('utf8'), length=2)\n",
    "        bow = spacy_lemma_gt_len(a[2].decode('utf-8'), length=2)\n",
    "        # maybe remove stop words\n",
    "        bow = u', '.join(bow)\n",
    "        results.append(u'{}\\t{{{}}}\\t{}\\t{}'.format(a[0], bow, score, '\\N'))\n",
    "    return(results)\n",
    "\n",
    "def append_raw_sentences(fname, annotations, score=None):\n",
    "    '''Appends annotations (list of lists) : [[id, title, abstract],...]\n",
    "    score (postgres boolean) :  t f \\N\n",
    "    '''\n",
    "    with codecs.open(fname, 'a', encoding = 'utf-8') as f:\n",
    "        for a in annotations:\n",
    "            f.write(u'{}\\t{}\\t{}\\N\\n'.format(a[0], a[2].decode('utf-8'), score))\n",
    "                    \n",
    "def append_annotated_sentences(fname, annotations):\n",
    "    ''' annotations (list of strings) : [\"id\\tbagofwords\\tpostgres_boolean\\t\\N\",...]'''\n",
    "    with codecs.open(fname, 'a', encoding = 'utf-8') as f:\n",
    "        for a in annotations:\n",
    "            a = a.replace('\"', '') # avoid postgres malformed array on unescaped quotes\n",
    "            f.write(a + '\\n')\n",
    "\n",
    "def main(args):\n",
    "    pass\n",
    "\n",
    "if '__name__' == 'main':\n",
    "     main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
