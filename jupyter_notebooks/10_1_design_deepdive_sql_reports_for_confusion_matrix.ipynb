{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: update to more recent and modular version of deepdive. The modularity may make some of these steps easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report confusion matrix stats from deepdive database.\n",
    "\n",
    "Using DeepDive : v0.7.0-0-gf4e6dfe.\n",
    "\n",
    "We have to jump through some hoops to get the confusion matrix based on our training as well as our test data due to the limited way DeepDive reports inference.\n",
    "\n",
    "We want the confusion matrix\n",
    "\n",
    "|  | true negative | true positive |\n",
    "|--|--------------- |--|--|\n",
    "|predicted negative | | |\n",
    "|predicted positive | | |\n",
    "\n",
    "The only true negative and true positive results deepdive gives us free is for the holdout fraction.\n",
    "\n",
    "We want to recover the full set of true positive and true negative, and be able to select that portion that was in the training set, and that portion that was in the 'test' or holdout set.\n",
    "\n",
    "We can obtain all these since we included copies of the full true 'negative' and 'positive' sets along with unknown observations.\n",
    "\n",
    "We might further have a set of 'known' unknonwns, those that were very likely to be positive because of the strong MeSH recovery of relevant articles.\n",
    "\n",
    "## see also 8_0_3_quick_auditory_test for some details on brief testing of these ideas.\n",
    "\n",
    "## Warning: Possible duplicates depending on sql reporting or table handling.\n",
    "We note that when DeepDive reports inference for the holdout portion of the labeled 'known' data it may report slightly different expect values vs. when the same inference is done on the same data when it is labeled 'unknown'. The difference does not seem to be strongly directional, maybe it is random, but we do not know.\n",
    "\n",
    "We handle this issue of non-perfect duplicates in the R script by choosing only one of the duplicate expect values for any given inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save inference table\n",
    "We'll use an external R script to generate the confusion matrix, so all we are doing here is extracting those IDs that are in the training data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception\n"
     ]
    }
   ],
   "source": [
    "# work within app directory to make sure connected to sql as per\n",
    "# deepdive db.url\n",
    "# OR disintermediate deepdive.\n",
    "app = '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception'\n",
    "%cd {app}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cmd = 'select sentence_id from _annotated_sentences_has_term_inference where has_term is not null order by sentence_id'\n",
    "#!deepdive sql eval \"{cmd}\" format=tsv > cc_holdout_ids.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT a.has_term, r.terms, a.sentence_id, expectation FROM _annotated_sentences_has_term_inference as a JOIN _raw_sentences as r ON a.sentence_id = r.sentence_id ORDER BY a.sentence_id'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = ('SELECT a.has_term, r.terms, a.sentence_id, expectation '\n",
    "       'FROM '\n",
    "       '_annotated_sentences_has_term_inference as a JOIN '\n",
    "       '_raw_sentences as r ON '\n",
    "       'a.sentence_id = r.sentence_id '\n",
    "       'ORDER BY a.sentence_id')\n",
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!deepdive sql eval \"{cmd}\" format=tsv > cc_all_predictions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX\n",
    "### A.1 Difference in predictions between holdout as known or unknown.\n",
    "\n",
    "The holdouts are reported in inference twice. Once as *labeled knowns* and once as *unkown knowns* due to our pseudocoding a duplicate of all knowns to unknowns. (But note the portion of the knowns used in training is only reported in the pseudocoded 'unknowns' state.)\n",
    "\n",
    "Not many of these, but enough we should be aware of it."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# cmd = ('SELECT DISTINCT r.terms as has_term,a.sentence_id,expectation INTO '\n",
    "#                'cc_test FROM '\n",
    "#                '_annotated_sentences_has_term_inference as a JOIN '\n",
    "#                '_raw_sentences as r ON '\n",
    "#                'a.sentence_id = r.sentence_id WHERE '\n",
    "#                'r.terms IS NOT NULL '\n",
    "#                'ORDER BY a.sentence_id') \n",
    "\n",
    "# !deepdive sql 'SELECT * FROM cc_test t1 JOIN (SELECT sentence_id FROM cc_test GROUP BY sentence_id HAVING COUNT(*) >= 2) t2 ON t1.sentence_id = t2.sentence_id'\n",
    "# has_term | sentence_id | expectation | sentence_id\n",
    "# ----------+-------------+-------------+-------------\n",
    "#  t        | 23827717    |       0.828 | 23827717\n",
    "#  t        | 23827717    |       0.844 | 23827717\n",
    "#  f        | 23462484    |           0 | 23462484\n",
    "#  f        | 23462484    |       0.002 | 23462484\n",
    "#  t        | 24821552    |       0.998 | 24821552\n",
    "#  t        | 24821552    |       0.992 | 24821552"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
