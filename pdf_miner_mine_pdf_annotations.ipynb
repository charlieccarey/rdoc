{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract annotations from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# from pdfminer.pdfparser import PDFParser\n",
    "# from pdfminer.pdfdocument import PDFDocument\n",
    "# from pdfminer.pdfpage import PDFPage\n",
    "# from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "# from pdfminer.pdfinterp import PDFResourceManager\n",
    "# from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "# from pdfminer.pdfdevice import PDFDevice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and parsing pdf with pdfminer.\n",
    "Most of this is per pdfminer doc.\n",
    "\n",
    "Note pdfminer documentation is fairly sparse and some big changes between versions.\n",
    "\n",
    "examples:\n",
    "\n",
    "https://dadruid5.wordpress.com/2014/08/14/getting-started-extracting-tables-with-pdfminer/\n",
    "http://slott-softwarearchitect.blogspot.com/2012/02/pdf-reading.html\n",
    "\n",
    "http://stackoverflow.com/questions/25248140/how-does-one-obtain-the-location-of-text-in-a-pdf-with-pdfminer\n",
    "\n",
    "This example especially describes the functions better and in context:\n",
    "\n",
    "http://denis.papathanasiou.org/posts/2010.08.04.post.html\n",
    "\n",
    "For information on pdf format and keys used in pdf:\n",
    "\n",
    "http://www.adobe.com/content/dam/Adobe/en/devnet/acrobat/pdfs/pdf_reference_1-7.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fname = '../me.pdf' # has several highlights in green.\n",
    "# fp = open(fname, 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boiler plate setting up parser etc.\n",
    "https://euske.github.io/pdfminer/programming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Create a PDF parser object associated with the file object.\n",
    "# parser = PDFParser(fp)\n",
    "# # Create a PDF document object that stores the document structure.\n",
    "# # Supply the password for initialization.\n",
    "# document = PDFDocument(parser) #, password) if password protected.\n",
    "# # Check if the document allows text extraction. If not, abort.\n",
    "# if not document.is_extractable:\n",
    "#     raise PDFTextExtractionNotAllowed\n",
    "# # Create a PDF resource manager object that stores shared resources.\n",
    "# rsrcmgr = PDFResourceManager()\n",
    "# # Create a PDF device object.\n",
    "# device = PDFDevice(rsrcmgr)\n",
    "# # Create a PDF interpreter object.\n",
    "# interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# # Process each page contained in the document.\n",
    "# for page in PDFPage.create_pages(document):\n",
    "#     interpreter.process_page(page)\n",
    "\n",
    "\n",
    "# my_pages = PDFPage.get_pages(fname, set([1])) # should be create_pages? get_pages deprecated?\n",
    "\n",
    "# p1 = list(my_pages)[0:1]\n",
    "# p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parser = PDFParser(fp)\n",
    "# document = PDFDocument(parser)\n",
    "# if not document.is_extractable:\n",
    "#     raise PDFTextExtractionNotAllowed\n",
    "# rsrcmgr = PDFResourceManager()\n",
    "\n",
    "# from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure, LTChar, LTAnno\n",
    "# from pdfminer.converter import PDFPageAggregator\n",
    "\n",
    "# laparams = LAParams() # setting layout analysis params\n",
    "# # Create a PDF page aggregator object.\n",
    "# device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "# interpreter = PDFPageInterpreter(rsrcmgr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### every page must be processed before we can work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layouts = []\n",
    "# for page in PDFPage.create_pages(document):\n",
    "#     interpreter.process_page(page)\n",
    "#     layouts.append(device.get_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pages = list(PDFPage.get_pages(fp, set()))\n",
    "# print(type(pages[0]))\n",
    "# #print(layouts) # not sure why we'd need this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LTPages with rectangles and rotations\n",
    "#print(layouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# annots = pages[0].annots.resolve() # list of pdfminer.pdftypes.PDFObjRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(len(annots))\n",
    "# print(type(annots[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how number of annots roughly corresponds to number of blocks of highlights visible in pdf.\n",
    "\n",
    "<img src='me_pdf.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refer to adobe documentation for annotation object keys, but here is a brief list\n",
    "\n",
    "A highlighted annotation has several key, value items.\n",
    "\n",
    "The most important to us are:\n",
    "\n",
    "- T: by convention, the annotator's name.\n",
    "- C: RGB color if 3 elements\n",
    "- NM: annotation name\n",
    "- Rect: location on page in user space units, \n",
    "- Contents: not avail here, but if avail, the text of\n",
    "- Popup: if the highlight was related to a popup annotation, the popup is here.\n",
    "\n",
    "The details on what the keys mean are spread across multiple tables in Adobe PDF Doc. This is because: \n",
    "- **highlight** annotation is a subtype of a **text markup** annotation (adds 2 fields).\n",
    "- **text markup** annotations are types of **markup annotations** (adding many fields including annotator name via T.)\n",
    "- **markup annotations** are types of **annotations** (several fields)\n",
    "\n",
    "Adobe documentation Table 8.3 **highlight** is a Text Markup Annotations which adds : Subtype /Highlight, QuadPoints \n",
    "\n",
    "- Adobe doc Section 8.4 annotations.\n",
    "- Adobe doc Table 8.15 keys definitions for all annotations.\n",
    "- Adobe doc Table 8.30 keys added for text markup annotations. (highlight is a subtype of text markup annotation)\n",
    "- Adobe doc Table 8.21 Additional entries to markup annotations.\n",
    "\n",
    "text markup (table 8.30) adds only:\n",
    "\n",
    "- subtype (we care about highlight subtype)\n",
    "- quad points\n",
    "- But note that AP, if present, has precedence over these quadpoints.\n",
    "\n",
    "AP (dictionary for how annotation appears):\n",
    "(This seems relevant to mouse scrollover effects and fine tuning of the bounding box of the annotations.)\n",
    "- table 8.15\n",
    "- section 8.4.4\n",
    "\n",
    "\n",
    "quad points  : (8 x n) where each is a word (X1,Y1,X2,Y2...XX1,YY1,...) so n points / 8 = number of words\n",
    "\n",
    "note AP takes precedence over quadpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining a couple annotations\n",
    "Note that annot 1 seems to not be of the 'highlight' subtype. Maybe it was a stray and invisible mark?\n",
    "\n",
    "Note that annot 0 is a 'highlight' subtype, we can see the name of the annotator with the 'T' flag.\n",
    "\n",
    "The Quadpoints should allow us to extract the text under the annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pprint.pprint(annots[0].resolve().items())\n",
    "# print('-----')\n",
    "# pprint.pprint(annots[1].resolve().items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if we had pdfquery working...\n",
    "# pdf.extract([\n",
    "#    ('last_name', ':in_bbox(\"315,680,395,700\")'),\n",
    "#    ('year', ':contains(\"Form 1040A (\")', lambda match: int(match.text()[-5:-1]))\n",
    "#    ])\n",
    "# text = pdf.pq('LTPage[page_index=\"0\"] :in_bbox(\"10,10,300,300\")').text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin functions for final solution\n",
    "\n",
    "### extract text using quadpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine, LTFigure, LTChar, LTAnno\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdftypes import PDFObjRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parser = PDFParser(fp)\n",
    "# document = PDFDocument(parser)\n",
    "# if not document.is_extractable:\n",
    "#     raise PDFTextExtractionNotAllowed\n",
    "# rsrcmgr = PDFResourceManager()\n",
    "\n",
    "\n",
    "# laparams = LAParams() # setting layout analysis params\n",
    "# # Create a PDF page aggregator object.\n",
    "# device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "# interpreter = PDFPageInterpreter(rsrcmgr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note, the coordinate system is from lower left (0, 0) to upper right.\n",
    "\n",
    "And the locations are as points.\n",
    "\n",
    "We need a little slop to capture some of the Wider and taller characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def in_bbox(bbox, bbox_target):\n",
    "    \"\"\"Returns True if bbox is within bbox_target\n",
    "    \n",
    "    x, y = 0, 0 is lower left of page\n",
    "    Note, we end up adding a bit of buffer space to increase tolerance \n",
    "    for the highlighting thickness. In some cases this is still not enough.\n",
    "    \n",
    "    TODO: rewrite other code, if no highlight found, increase the tolerances here.\n",
    "    \"\"\"\n",
    "    y_buff = 1.0\n",
    "    bx0, by0, bx1, by1 = bbox\n",
    "    x0, y0, x1, y1 = bbox_target\n",
    "    retval = False\n",
    "    #if bx0 >= x0 - 1 and by0 >= y0 - 1 and bx1 <= x1 + 1 and by1 <= y1 + 1:\n",
    "    if bx0 >= x0 - 1 and by0 >= y0 - 1 and bx1 <= x1 + 1 and by1 <= y1 + 3: # y1 + 2 sufficient for most.\n",
    "        retval = True\n",
    "    return(retval)\n",
    "\n",
    "in_bbox([98.1348, 498.413, 289.085, 507.747], [95, 400, 300, 550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_layout(layout, bbox_target):\n",
    "    \"\"\"Extract text within bbox.\n",
    "    \n",
    "    modified from:\n",
    "    \n",
    "    http://stackoverflow.com/questions/25248140/how-does-one-obtain-the-location-of-text-in-a-pdf-with-pdfminer\n",
    "    \"\"\"\n",
    "    chars = []\n",
    "    for lt_obj in layout:\n",
    "        # print(lt_obj.__class__.__name__)\n",
    "        # print(lt_obj.bbox)\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            for lt_line_obj in lt_obj:\n",
    "                # print(lt_line_obj.get_text())\n",
    "                # print(lt_line_obj.bbox)\n",
    "                capture = False\n",
    "                prev = None\n",
    "                for lt_subline_obj in lt_line_obj:\n",
    "                    if isinstance(lt_subline_obj, LTChar):\n",
    "                        # LTAnno (spaces...) have no position\n",
    "                        # if position is in quad points, print\n",
    "                        capture = in_bbox(lt_subline_obj.bbox, bbox_target)\n",
    "                        if capture:\n",
    "                            # print('previous {}'.format(prev)) # as check if we miss a leading character to check how much slop is needed.\n",
    "                            # print(lt_subline_obj.bbox)\n",
    "                            chars.append(lt_subline_obj.get_text())\n",
    "                        prev = lt_subline_obj.bbox\n",
    "                    if isinstance(lt_subline_obj, LTAnno):\n",
    "                        if capture:\n",
    "                            chars.append(lt_subline_obj.get_text())\n",
    "    return(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #parse_layout(layouts[0])\n",
    "# test_quad = [98.1348, 507.747, 289.085, 507.747,\n",
    "#              98.1348, 498.413, 289.085, 498.413]\n",
    "# #[90, 500, 300, 510])\n",
    "# corners = [4, 5, 2, 3]\n",
    "# test_box = [test_quad[i] for i in corners]\n",
    "# test_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption the quadrilateral is not rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #test_box = [51.0236, 485.997, 289.042, 495.332]\n",
    "# #parse_layout(layouts[0], [105.28789118, 498.3230095, 109.74117338, 507.6579657])\n",
    "# #parse_layout(layouts[0], test_box)\n",
    "# testA = [98.1348, 507.747, 289.085, 507.747, 98.1348, 498.413, 289.085, 498.413]\n",
    "# #testA = [98.1347, 507.747, 289.085, 507.747, 98.1347, 498.413, 289.085, 498.413]\n",
    "# testA = [testA[i] for i in corners]\n",
    "# parse_layout(layouts[0],testA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### loop through all annotations\n",
    "#for each annotation\n",
    "#  parse quad points into bbox\n",
    "#  for each bbox\n",
    "#      append bbox characters\n",
    "#  concat bbox characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def quads_to_boxes(quads):\n",
    "    '''Returns bounding box from quad points.\n",
    "    \n",
    "    A single quadpoint is 8 positions long to specify x, y locations.\n",
    "    We assume all quadpoints are defining non-rotated text and therefore \n",
    "    can be specified more simply as 4 coordinate boxes.\n",
    "    \n",
    "    The box returned is [x0, y0, x1, y1] where x0 and y0 are closest\n",
    "    to bottom left corner of page.\n",
    "    \n",
    "    example quad : \n",
    "    \n",
    "        [98.1348, 507.747, 289.085, 507.747,\n",
    "         98.1348, 498.413, 289.085, 498.413]\n",
    "\n",
    "    example box from this quad :\n",
    "       \n",
    "       (we get this from elements [4, 5, 2, 3] )\n",
    "       \n",
    "       [98.1348, 498.413, 289.085, 507.747]\n",
    "    '''\n",
    "    boxes = []\n",
    "    xyxy = [4, 5, 2, 3] # corners of box from quads\n",
    "    for i in range(0, len(quads), 8):\n",
    "        box_idx = [j+i for j in xyxy]\n",
    "        box = [quads[k] for k in box_idx]\n",
    "        boxes.append(box)\n",
    "    return(boxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_anno_boxes(annots):\n",
    "    #test quads_to_boxes\n",
    "    boxes = []\n",
    "    for anno in annots:\n",
    "        #TODO: make sure we have annotation type is highlight.\n",
    "        anno_d = dict(anno.resolve().items())\n",
    "        if 'QuadPoints' not in anno_d:\n",
    "            continue\n",
    "        annotator = anno_d['T']\n",
    "        color = anno_d['C']\n",
    "        quads = anno_d['QuadPoints']\n",
    "        these_boxes = quads_to_boxes(quads)\n",
    "        boxes.extend(these_boxes)\n",
    "    return(boxes)\n",
    "\n",
    "#boxes = get_anno_boxes(annots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by boxes is complex with 2 columns of pdf text...\n",
    "Sorting by boxes is complex with 2 columns of pdf text and with annotations starting or ending anywhere in a line. In addition, lines may be slightly offset from each other in the different columns.\n",
    "\n",
    "Together this suggests we should instead pull out our annotations by going straight through the lines and checking for annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boxes = sorted(boxes, key = lambda x : (-x[3], x[0]))\n",
    "# highlights = []\n",
    "# for box in boxes:\n",
    "#     print(box)\n",
    "#     print(''.join(parse_layout(layouts[0], box)))\n",
    "#     highlight = ''.join(parse_layout(layouts[0], box))\n",
    "#     highlight = highlight.replace('-\\n', '')\n",
    "#     highlight = highlight.replace('\\n', ' ')\n",
    "#     highlights.append(highlight)\n",
    "#     # replace newline splits\n",
    "# print(' '.join(highlights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print regions within highlights\n",
    "We have 52 bboxes that correspond to highlights.\n",
    "\n",
    "We loop through all the text boxes in layout cleaning them up.\n",
    "\n",
    "Then we loop through a second time extracting all our hightlighted text or sentences containing that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bboxes = [[98.1348, 498.413, 289.085, 507.747], [51.0236, 485.997, 289.042, 495.332]]\n",
    "#bbox = [51.0236, 485.997, 289.042, 495.332] # true\n",
    "#bbox = [51.0236, 4.997, 19.042, 41.332] # false\n",
    "def in_bboxes(bbox_target, bboxes):\n",
    "    '''Returns True if the target is within any of the bboxes'''\n",
    "    in_target = map(lambda b: in_bbox(bbox_target, b), bboxes)\n",
    "    return(any(in_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bbox_text(LTText):\n",
    "    '''Gets text from LTTextBox or LTTextLine if it is within bbox.\n",
    "    \n",
    "    Note: these are generally LTTextBoxHorizontals'''\n",
    "    bbox_text = [LTText.bbox, []]\n",
    "    for line in LTText: # LTTextLineHorizontal\n",
    "        for char_or_anno in line:\n",
    "            if isinstance(char_or_anno, LTChar):\n",
    "                char_bbox = char_or_anno.bbox\n",
    "                this_bbox_char = (char_bbox, char_or_anno.get_text())\n",
    "                bbox_text[1].append(this_bbox_char)\n",
    "            if isinstance(char_or_anno, LTAnno): # LTAnno is spaces etc (not annotation, and no bbox)\n",
    "                this_bbox_char = (char_bbox, char_or_anno.get_text())\n",
    "                bbox_text[1].append(this_bbox_char)\n",
    "    return(bbox_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_sort_bboxes(bbox_1, bbox_2):\n",
    "    '''joins 2 bboxes together returning one bbox.\n",
    "    \n",
    "    Assumes 1 is within 2\n",
    "    Takes the overall position from first bbox, \n",
    "    joins and sorts all the characters and their positoins.'''\n",
    "    bbox = bbox_2[0]\n",
    "    chars = bbox_1[1] + bbox_2[1]\n",
    "    chars = sorted(chars, key=lambda c: (-c[0][3], c[0][0]))\n",
    "    new_bbox = [bbox, chars]\n",
    "    return(new_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sort_all_chars_in_all_bboxes(layout):\n",
    "    '''Combines chars from textboxes or textlines if one is contained \n",
    "    within other's region.\n",
    "    \n",
    "    This is most helpful where pdf lines are made up of multiple \n",
    "    LTTextLines such as sometimes happens at end of columns.\n",
    "    \n",
    "    '''\n",
    "    def loop_replace(restart, all_bbox_texts):\n",
    "        drop = []\n",
    "        for i in range(0, len(all_bbox_texts)):\n",
    "            for j in range(i + 1, len(all_bbox_texts)):\n",
    "                i_in_j = in_bbox(all_bbox_texts[i][0], all_bbox_texts[j][0])\n",
    "                j_in_i = in_bbox(all_bbox_texts[j][0], all_bbox_texts[i][0])\n",
    "                if i_in_j:\n",
    "                    new_bbox_text = join_sort_bboxes(all_bbox_texts[i], all_bbox_texts[j])\n",
    "                elif j_in_i:\n",
    "                    new_bbox_text = join_sort_bboxes(all_bbox_texts[j], all_bbox_texts[i])\n",
    "                if i_in_j or j_in_i: # shouldn't matter if we are dropping j or i\n",
    "                    all_bbox_texts[i] = new_bbox_text\n",
    "                    drop.append(j)\n",
    "                    restart = True\n",
    "        all_bbox_texts = [all_bbox_texts[z] for z in range(0, len(all_bbox_texts)) if z not in drop]\n",
    "#         print(drop)\n",
    "#         print(len(all_bbox_texts))\n",
    "        return(restart, all_bbox_texts)\n",
    "    \n",
    "    #TODO: test completeness on other orderings of contained text.\n",
    "    def join_if_within(all_bbox_texts):\n",
    "        '''Returns list of bbox_texts, joining together a region \n",
    "        with its encompassing region.'''\n",
    "        restart = True\n",
    "        n = 0\n",
    "        while restart:\n",
    "            n = n+1\n",
    "            restart = False\n",
    "            restart, all_bbox_texts = loop_replace(restart, all_bbox_texts)\n",
    "        return(all_bbox_texts)\n",
    " \n",
    "    i_boxes = [] #[None] * len(layout) # may not use all...\n",
    "    bboxes = []\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            bboxes = get_bbox_text(lt_obj)#, bbox)\n",
    "            i_boxes.append(bboxes)\n",
    "    i_boxes = join_if_within(i_boxes)\n",
    "    return(i_boxes)\n",
    "\n",
    "# for b in layouts[0]:\n",
    "#     print(b)\n",
    "\n",
    "# c = sort_all_chars_in_all_bboxes(layouts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_only_boxes(boxes, bbox_targets):\n",
    "    \"\"\"Extract text within bboxes. For example, \n",
    "    our target may be highlighted regions.\n",
    "    \n",
    "    Proceeds through all text, capturing if in target regions.\n",
    "    \n",
    "    modified from:\n",
    "    \n",
    "    http://stackoverflow.com/questions/25248140/how-does-one-obtain-the-location-of-text-in-a-pdf-with-pdfminer\n",
    "    \n",
    "    params:\n",
    "        boxes [[bbox, [(bbox, char), ...]]] : a cleaned up, ordered list of textregions.\n",
    "        bbox_targets [x0, y0, x1, y1] : rectangle corresponding to region we want to extract.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # run through all characters, grabbing them if they are in bbox_targets\n",
    "    for b_region in boxes:\n",
    "        for ch in b_region[1]:\n",
    "            if in_bboxes(ch[0], bbox_targets):\n",
    "                result.append(ch[1])\n",
    "            elif ch[1] == '.': # tag ends of regions, may end up with many of these\n",
    "                result.append(ch[1])\n",
    "            else:\n",
    "                result.append(' ') # in case multiple annotations in same region make sure there is a space between them.\n",
    "                                   # but side effect is introducing many space characters.\n",
    "    result = ''.join(result)\n",
    "    # extensive cleanup of our parsing! what a mess! could be simpler?\n",
    "    result = result.strip()\n",
    "    result = re.sub('[ ][ ]+', ' ', result) # introduced while we tried to keep a few necessary spaces.\n",
    "    result = re.sub('( \\\\.){1,}', '.', result) # introduced from keeping all sentence terminators.\n",
    "    result = re.sub('^. ', '', result) # clean up sentence beginnings.\n",
    "    result = re.sub('([a-z])[.]+([A-Za-z])', '\\\\1. \\\\2', result) # clean up sentence boundaries\n",
    "    result = re.sub(' [.]([A-Z])', '. \\\\1', result) # clean up sentence boundaries.\n",
    "    result = re.sub('[.][.]+', '', result) # trim extra 'sentence or phrase ending' tags.\n",
    "    result = result.replace('-\\n', '') # not entirely safe! e.g. force-\\nmatching ideally is force-matching.\n",
    "    result = result.replace('\\n', ' ')\n",
    "    result = re.sub('[?,!:;.]+[.]', '.', result) # 'highlight ends on punct' common corner cases.\n",
    "    if len(result) > 0:\n",
    "        result = result + '.' # make sure there is an ending.               \n",
    "        result = re.sub('[ .]?[ .]?[ .].$', '.', result) # clean sentence endings.\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test = ' . . .atest'\n",
    "# test = ' . . .atest. a test. . . a test'\n",
    "\n",
    "# test = re.sub('( \\\\.)+', '.', test)\n",
    "# test = ' . . .atest. a test,. . . a test. .'\n",
    "# #test = re.sub('( \\\\.)+', '.', test)\n",
    "# result = re.sub('[ .]?[ .]?[ .]?$', '.', test)\n",
    "# print(result)\n",
    "\n",
    "# test =  'Thus, these alleles may affect performance particularly when sustained dopamine release is necessary..'\n",
    "# result = re.sub('[ .][.]$', '.', test)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract_only_boxes(c, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_pages(pages, layouts, first_n_pages):\n",
    "    results = []\n",
    "    for i, p in enumerate(pages[0:first_n_pages]):\n",
    "        logging.debug('Processing page : {}'.format(i))\n",
    "        annots = []\n",
    "        if isinstance(p.annots, PDFObjRef):\n",
    "            annots = p.annots.resolve()\n",
    "        elif p.annots is not None: # annotations are in a list\n",
    "            logging.debug('Annotations in list...')\n",
    "            for a in p.annots:\n",
    "                annots.append(a)\n",
    "        else:\n",
    "            logging.debug('No annotations found for page : {}'.format(i))\n",
    "        annot_boxes = get_anno_boxes(annots)\n",
    "        # gat all the text regions from this page,\n",
    "        # reordering some elements if necessary.\n",
    "        c = sort_all_chars_in_all_bboxes(layouts[i])\n",
    "    \n",
    "        # capture all the text under the annotations.\n",
    "        page_result = extract_only_boxes(c, annot_boxes)\n",
    "        logging.debug(page_result)\n",
    "        results.append(page_result)\n",
    "    results = ' '.join(results).strip()\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_pdf(fname):\n",
    "    '''Parse highlighted annotations out of pdf.'''\n",
    "    logging.info('processing file : {}'.format(fname))\n",
    "\n",
    "    fp = open(fname, 'rb')\n",
    "    parser = PDFParser(fp)\n",
    "    document = PDFDocument(parser)\n",
    "    if not document.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "\n",
    "    laparams = LAParams() # setting layout analysis params\n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    # work with individual pages\n",
    "    layouts = []\n",
    "    for page in PDFPage.create_pages(document):\n",
    "        interpreter.process_page(page)\n",
    "        layouts.append(device.get_result())\n",
    "\n",
    "#TODO: italics are getting sorted higher than non-italics... fix by giving extra range to sort on y?\n",
    "#TODO: italics (cont.) sometimes the italicized text is moved within the line, sometimes dropped entirely.\n",
    "\n",
    "    # get the annotation boxes for the page\n",
    "    pages = list(PDFPage.get_pages(fp, set()))\n",
    "\n",
    "    results = parse_pages(pages, layouts, first_n_pages=2)\n",
    "    fp.close()\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spacy_split_sentences(text):\n",
    "    sentences = []\n",
    "    #doc = nlp(text.decode('utf8')) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    doc = nlp(text) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    for span in doc.sents:\n",
    "        #sentences.append(u''.join(doc[i].string for i in range(span.start, span.end)).encode('utf-8').strip())\n",
    "        sentences.append(''.join(doc[i].string for i in range(span.start, span.end)))#.strip())\n",
    "    sentences = '\\n'.join(sentences)\n",
    "    sentences = sentences + '\\n'\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "from spacy.en import English\n",
    "\n",
    "logger = logging.getLogger() # use logger set by jupyter.\n",
    "#logger.setLevel(logging.INFO)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "nlp = English(parser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests to be sure annotations are split into maximal sentences.\n",
    "Not necessarily full sentences. Just want to make sure if annotations don't include sentence terminals, we have introduced a sentence terminal as needed. \n",
    "\n",
    "Some of these tests are especially for result endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP01_05_24333745_cc_ANNOTATED.pdf\n",
      "DEBUG:root:Processing page : 0\n",
      "DEBUG:root:\n",
      "DEBUG:root:Processing page : 1\n",
      "DEBUG:root:No annotations found for page : 1\n",
      "DEBUG:root:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%cd /Users/ccarey/Documents/Projects/NAMI/rdoc\n",
    "\n",
    "# bold text\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AR03_04_25136085_mk_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# problem document, highlights are shifted.\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AR03_03_25160677_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# problem document, highlights are shifted.\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AR03_01_25261920_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# #problem document, highlights are shifted, even though the preview looks ok.\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AR00_03_25788679_cc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# even though my highlights look 'narrower' than others, they seem ok\n",
    "#  \n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR01_20695690_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "# print('---------------')\n",
    "\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR01_21699821_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR01_21849230_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# problem with list, maybe as dict instead of list?\n",
    "# ERRORS as no .resolve for dict method... anno_d = dict(anno.resolve().items())\n",
    "# print('---------------')\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/_02_LS00_03_25913552_jl_IRRELEVANT.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# not catching annotation. Needed increased height tolerance (+3)\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AP00_01_25774613_cc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "# Required much larger height tolerance (+/- 7?)\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/02_AP01_05_24333745_cc_ANNOTATED.pdf'\n",
    "test = parse_pdf(test_sentence_split)\n",
    "print(test)\n",
    "print('------')\n",
    "test = spacy_split_sentences(test)\n",
    "print(test)\n",
    "\n",
    "\n",
    "# print('---------------')\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR04_22438994_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "\n",
    "\n",
    "# annotations are in a list, should have results...\n",
    "# But everything seems shifted quite a large amount. (relative to pages?, relative to parant?)\n",
    "# print('---------------')\n",
    "#test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR03_24806675_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "# {'Dest': 'n33', 'Subtype': /Link, 'Type': /Annot, 'Border': [0, 0, 0], 'Rect': [195.003, 309.835, 293.202, 322.5]}\n",
    "# many Dest\n",
    "# {'C': [1.0, 1.0, 0.0], 'Popup': <PDFObjRef:386>, 'NM': 'c9e8becc-bb81-4687-81b2-74c7c475a53f', 'P': <PDFObjRef:323>, 'F': 4, 'Type': /Annot, 'M': \"D:20151021133008-06'00'\", 'Subtype': /Highlight, 'AP': {'N': <PDFObjRef:324>}, 'T': 'NAMI', 'QuadPoints': [329.524, 508.0, 374.55, 508.0, 329.524, 497.0, 374.55, 497.0], 'CreationDate': \"D:20151021133008-06'00'\", 'Subj': 'Highlight', 'Rect': [326.587, 496.656, 377.487, 508.344]}\n",
    "# {'Parent': <PDFObjRef:385>, 'F': 28, 'Open': False, 'Subtype': /Popup, 'Type': /Annot, 'Rect': [594.0, 388.0, 774.0, 508.0]}\n",
    "# [[329.524, 497.0, 374.55, 508.0], [197.297, 460.95, 553.187, 472.0], [51.4987, 449.0, 553.194, 460.0], [51.4987, 437.0, 288.023, 448.0]]\n",
    "\n",
    "# try again, but more manually... observe works when we shift the bboxes.\n",
    "#test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR03_24806675_tc_ANNOTATED.pdf'\n",
    "## annot_boxes = [[329.524, 497.0, 374.55, 508.0], [197.297, 460.95, 553.187, 472.0], [51.4987, 449.0, 553.194, 460.0], [51.4987, 437.0, 288.023, 448.0]] # is off correct words, in fact no words.\n",
    "# x = 9 # maybe the entire page's lower corner is shifted? Or the abstract is shifted?\n",
    "# annot_boxes = [[329.524 - x, 497.0 - x, 374.55 - x, 508.0 - x], [197.297 - x, 460.95 - x, 553.187 - x, 472.0 - x], [51.4987 - x, 449.0 - x, 553.194 - x, 460.0 - x], [51.4987 - x, 437.0 - x, 288.023 - x, 448.0 - x]] # shifted, is on correct words\n",
    "# fp = open(test_sentence_split, 'rb')\n",
    "# parser = PDFParser(fp)\n",
    "# document = PDFDocument(parser)\n",
    "# if not document.is_extractable:\n",
    "#     raise PDFTextExtractionNotAllowed\n",
    "# rsrcmgr = PDFResourceManager()\n",
    "# laparams = LAParams() # setting layout analysis params\n",
    "# device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "# interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# layouts = []\n",
    "# for page in PDFPage.create_pages(document):\n",
    "#     interpreter.process_page(page)\n",
    "#     layouts.append(device.get_result())\n",
    "# pages = list(PDFPage.get_pages(fp, set()))\n",
    "# c = sort_all_chars_in_all_bboxes(layouts[0])\n",
    "# page_result = extract_only_boxes(c, annot_boxes)\n",
    "# print(page_result)\n",
    "\n",
    "#annotations are in a list, but list works.\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR04_23941878_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)\n",
    "# {'A': {'S': /URI, 'URI': 'http://dx.doi.org/10.1155/2014/627892'}, 'Subtype': /Link, 'C': [0, 0, 1], 'Border': [0, 0, 0], 'Rect': [50.59, 705.69, 171.72, 713.66]}\n",
    "# {'C': [1.0, 1.0, 0.0], 'Popup': <PDFObjRef:305>, 'NM': 'eef900fb-9fe2-42f1-8f22-f95089bdb9d7', 'P': <PDFObjRef:269>, 'F': 4, 'Type': /Annot, 'M': \"D:20151028154411-06'00'\", 'Subtype': /Highlight, 'AP': {'N': <PDFObjRef:270>}, 'T': 'NAMI', 'QuadPoints': [313.351, 334.9, 339.238, 334.9, 313.351, 322.805, 339.238, 322.805], 'CreationDate': \"D:20151028154411-06'00'\", 'Subj': 'Highlight', 'Rect': [310.122, 322.427, 342.467, 335.278]}\n",
    "# {'Parent': <PDFObjRef:304>, 'F': 28, 'Open': False, 'Subtype': /Popup, 'Type': /Annot, 'Rect': [600.05, 214.9, 780.05, 334.9]}\n",
    "# ... C and Parent alternating\n",
    "\n",
    "# annotations are in a list, but list works.\n",
    "# test_sentence_split = './pdfs/all_pdfs_annotated_pmid_names/03_AR05_24980898_tc_ANNOTATED.pdf'\n",
    "# test = parse_pdf(test_sentence_split)\n",
    "# print(test)\n",
    "# print('------')\n",
    "# test = spacy_split_sentences(test)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### handling the unicode\n",
    "Seems easiest to handle unicode only in writing back the resulting parsed sentences. (i.e. single point of unicode intervention.)\n",
    "\n",
    "Either:\n",
    "\n",
    "with codecs.open(fout, 'w', 'utf-8') as f:\n",
    "    ...\n",
    "    f.write(...)\n",
    "\n",
    "Or:\n",
    "\n",
    "with open(fout, 'w') as f:\n",
    "    sentences = spacy_split_sentences(v)\n",
    "    f.write(...encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few test cases\n",
    "\n",
    "Test files for 2 ways highlights may be organized in pdf.\n",
    " \n",
    "    f = './some_test_pdfs/02_AG05_02_ANNOTATED_jl.pdf' # has a single  annotation obj resolving to list of annotation\n",
    "  \n",
    "    f = './some_test_pdfs/02_AP06_03_ANNOTATED_jl.pdf' # has a list of annotations\n",
    "\n",
    "Test, includes bubble annotation\n",
    "\n",
    "    f = './some_test_pdfs/02_LS05_01_24376698_cc_ANNOTATED.pdf # includes bubble annotation)\n",
    "\n",
    "Test files for annotations on various pages\n",
    "\n",
    "    f = './some_test_pdfs/03_AR01_25017671_tc_ANNOTATED.pdf # has annotations, but they are on page 2.\n",
    "  \n",
    "    f = './some_test_pdfs/03_AR01_21699821_tc_ANNOTATED.pdf # has  annotations, but split across page 1,2\n",
    "\n",
    "TODO: Test files for italics.\n",
    "\n",
    "    f = ./some_test_pdfs/02_AP06_03_ANNOTATED_mk.pdf (entirely drops n from n= )\n",
    "  \n",
    "    f = ./some_test_pdfs/02_AG05_02_ANNOTATED_jl.pdf (italics remain but are rearranged.)\n",
    "\n",
    "TODO OR JUST CHECK EMPTY RESULTS: Test files for highlight or text has shifted coordinates.\n",
    "\n",
    "    f = ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_24806675_tc_ANNOTATED.pdf'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem documents to annotate entirely by hand:\n",
    "\n",
    "These were easily identified on OS X in Preview... \n",
    "\n",
    "    The highlights on these documents are obviously shifted when viewing as preview of document (but note: after opening in preview they look normal).\n",
    "    \n",
    "- Developmental Cognitive Neuroscience\n",
    "  + 02_AR03_01_25261920\n",
    "  + 02_AR03_03_25160677\n",
    "- Neurobiology of disease\n",
    "  + 03_AR03_24806675\n",
    "- The Journal of Neuroscience\n",
    "  + 02_AR00_02_25834059\n",
    "  + 02_AR00_03_25788679\n",
    "  + 02_LS05_02_20685988\n",
    "  \n",
    "Following have some other error... annotations in list.\n",
    "\n",
    "  + _02_AP07_02_24804717_mk_ANNOTATED\n",
    "  + _02_LS00_03_25913552_mk_ANNOTATED_IRRELEVANT\n",
    "  \n",
    "I had a bubble here, then tried to remove it, but failed?\n",
    "\n",
    "  + _02_LS05_01_24376698_cc\n",
    "  \n",
    "Expected unicode, got string\n",
    "\n",
    "  + _02_AR01_05_22379245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_files(path, annotator):\n",
    "    # PUBMED ID in file name like: 03_AR05_23622762_mk_ANNOTATED\n",
    "    f_pattern = path + '*_[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]_' + annotator + '*.pdf'\n",
    "    files = glob.glob(f_pattern)\n",
    "    return(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_annotations_by_annotator(f_path_plus, result_dir, annotator):\n",
    "    '''Set output file and write annotations, 1 per line \n",
    "    for this annotator for all files for this annotator'''\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    files = get_files(f_path_plus, annotator)\n",
    "    results_d = {}\n",
    "    for f in files:\n",
    "        f_result = parse_pdf(f)\n",
    "        results_d.update({f : f_result})\n",
    "        # print(results_d)\n",
    "    for k,v in results_d.items():\n",
    "        bn = os.path.basename(k)\n",
    "        bn = os.path.splitext(bn)[0] + '.txt'\n",
    "        fout = os.path.join(result_dir, bn)\n",
    "        with codecs.open(fout, 'w', 'utf-8') as f:\n",
    "            print(bn)\n",
    "            sentences = spacy_split_sentences(v)\n",
    "            f.write(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## renamed 02 batched annotations towards their pubmed ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP00_03_25773639_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP01_03_24740391_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP07_05_21531705_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP08_05_21957257_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP11_03_23558179_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR00_05_25734385_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_01_23647728_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_02_23083918_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_04_22575329_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_05_22379245_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_02_25197810_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_04_25136085_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_05_25126038_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_01_25142564_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_02_25126029_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_03_24470693_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_04_24333377_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_05_24293773_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_01_24116095_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_02_24101292_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_03_24045586_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_04_23954763_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_05_23646134_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR07_01_20815182_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS00_05_25898427_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS06_04_24511281_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS08_04_24933724_tc_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_20695690_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_21699821_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_21849230_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_25017671_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_24725811_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_25258728_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_25348131_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_22379238_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_22438994_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23452958_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23709163_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23904684_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23941878_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23074247_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23088207_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23143607_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23622762_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_24770625_tc_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_24980898_tc_ANNOTATED.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc\n",
      "03_AR05_23622762_tc_ANNOTATED.txt\n",
      "03_AR04_23709163_tc_ANNOTATED.txt\n",
      "02_AR03_04_25136085_tc_ANNOTATED.txt\n",
      "02_AR01_05_22379245_tc_ANNOTATED.txt\n",
      "03_AR04_22379238_tc_ANNOTATED.txt\n",
      "02_AP00_03_25773639_tc_IRRELEVANT.txt\n",
      "02_AR04_05_24293773_tc_ANNOTATED.txt\n",
      "03_AR04_23941878_tc_ANNOTATED.txt\n",
      "02_AP07_05_21531705_tc_ANNOTATED.txt\n",
      "03_AR01_20695690_tc_ANNOTATED.txt\n",
      "03_AR01_25017671_tc_ANNOTATED.txt\n",
      "02_LS08_04_24933724_tc_IRRELEVANT.txt\n",
      "02_AR03_05_25126038_tc_ANNOTATED.txt\n",
      "02_AR05_02_24101292_tc_ANNOTATED.txt\n",
      "02_AP11_03_23558179_tc_IRRELEVANT.txt\n",
      "03_AR03_24725811_tc_ANNOTATED.txt\n",
      "02_LS00_05_25898427_tc_IRRELEVANT.txt\n",
      "03_AR05_23088207_tc_ANNOTATED.txt\n",
      "02_AR05_04_23954763_tc_ANNOTATED.txt\n",
      "02_AR04_01_25142564_tc_ANNOTATED.txt\n",
      "03_AR05_23143607_tc_ANNOTATED.txt\n",
      "03_AR05_23074247_tc_ANNOTATED.txt\n",
      "02_AR04_04_24333377_tc_ANNOTATED.txt\n",
      "03_AR05_24770625_tc_ANNOTATED.txt\n",
      "03_AR04_23904684_tc_ANNOTATED.txt\n",
      "03_AR04_22438994_tc_ANNOTATED.txt\n",
      "02_AR05_05_23646134_tc_ANNOTATED.txt\n",
      "03_AR01_21699821_tc_ANNOTATED.txt\n",
      "02_AR07_01_20815182_tc_ANNOTATED.txt\n",
      "03_AR03_25258728_tc_ANNOTATED.txt\n",
      "02_AP01_03_24740391_tc_ANNOTATED.txt\n",
      "02_AR04_03_24470693_tc_ANNOTATED.txt\n",
      "02_AR05_01_24116095_tc_ANNOTATED.txt\n",
      "02_AR01_01_23647728_tc_ANNOTATED.txt\n",
      "02_AP08_05_21957257_tc_ANNOTATED.txt\n",
      "02_AR05_03_24045586_tc_ANNOTATED.txt\n",
      "02_AR01_04_22575329_tc_ANNOTATED.txt\n",
      "03_AR03_25348131_tc_ANNOTATED.txt\n",
      "03_AR05_24980898_tc_ANNOTATED.txt\n",
      "02_AR01_02_23083918_tc_IRRELEVANT.txt\n",
      "02_LS06_04_24511281_tc_ANNOTATED.txt\n",
      "02_AR00_05_25734385_tc_IRRELEVANT.txt\n",
      "02_AR04_02_25126029_tc_ANNOTATED.txt\n",
      "02_AR03_02_25197810_tc_ANNOTATED.txt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AG05_01_23928891_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AG05_02_23744445_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP03_05_21613467_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP04_02_22447249_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP06_03_21319926_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP08_01_24023823_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AP11_02_24231418_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR00_05_25734385_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_01_23647728_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_02_23083918_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_04_22575329_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR01_05_22379245_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_02_25197810_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_04_25136085_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR03_05_25126038_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_01_25142564_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_02_25126029_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_03_24470693_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR04_04_24333377_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_01_24116095_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_02_24101292_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_03_24045586_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_04_23954763_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR05_05_23646134_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_AR07_01_20815182_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS02_01_24285346_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS06_02_25036160_mk_ANNOTATED_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS06_05_23957953_mk_ANNOTATED_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS07_01_25280468_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS07_04_24388670_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS08_01_25154749_mk_ANNOTATED_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/02_LS08_05_24359877_mk_ANNOTATED_IRRELEVANT.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_20695690_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_21699821_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_21849230_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR01_25017671_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_24725811_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_25258728_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR03_25348131_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_22379238_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_22438994_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23452958_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23709163_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23904684_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR04_23941878_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23074247_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23088207_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23143607_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_23622762_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_24770625_mk_ANNOTATED.pdf\n",
      "INFO:root:processing file : ./pdfs/all_pdfs_annotated_pmid_names/03_AR05_24980898_mk_ANNOTATED.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "03_AR04_23452958_tc_ANNOTATED.txt\n",
      "03_AR01_21849230_tc_ANNOTATED.txt\n",
      "02_LS06_02_25036160_mk_ANNOTATED_IRRELEVANT.txt\n",
      "02_AP03_05_21613467_mk_ANNOTATED.txt\n",
      "02_AR00_05_25734385_mk_ANNOTATED.txt\n",
      "02_AR05_03_24045586_mk_ANNOTATED.txt\n",
      "03_AR01_25017671_mk_ANNOTATED.txt\n",
      "02_LS07_01_25280468_mk_ANNOTATED.txt\n",
      "03_AR03_24725811_mk_ANNOTATED.txt\n",
      "03_AR04_23452958_mk_ANNOTATED.txt\n",
      "03_AR04_23709163_mk_ANNOTATED.txt\n",
      "02_AP06_03_21319926_mk_ANNOTATED.txt\n",
      "03_AR04_22438994_mk_ANNOTATED.txt\n",
      "03_AR05_24770625_mk_ANNOTATED.txt\n",
      "03_AR04_23904684_mk_ANNOTATED.txt\n",
      "03_AR05_23143607_mk_ANNOTATED.txt\n",
      "02_AR05_01_24116095_mk_ANNOTATED.txt\n",
      "02_AG05_02_23744445_mk_ANNOTATED.txt\n",
      "02_LS07_04_24388670_mk_ANNOTATED.txt\n",
      "02_LS08_05_24359877_mk_ANNOTATED_IRRELEVANT.txt\n",
      "02_AR05_05_23646134_mk_ANNOTATED.txt\n",
      "02_AR01_04_22575329_mk_ANNOTATED.txt\n",
      "02_AP11_02_24231418_mk_ANNOTATED.txt\n",
      "03_AR01_21849230_mk_ANNOTATED.txt\n",
      "03_AR05_23088207_mk_ANNOTATED.txt\n",
      "03_AR05_23074247_mk_ANNOTATED.txt\n",
      "02_AR03_02_25197810_mk_ANNOTATED.txt\n",
      "03_AR01_20695690_mk_ANNOTATED.txt\n",
      "03_AR05_23622762_mk_ANNOTATED.txt\n",
      "02_AR01_01_23647728_mk_ANNOTATED.txt\n",
      "02_LS08_01_25154749_mk_ANNOTATED_IRRELEVANT.txt\n",
      "02_AR07_01_20815182_mk_ANNOTATED.txt\n",
      "02_AR05_02_24101292_mk_ANNOTATED.txt\n",
      "02_LS02_01_24285346_mk_ANNOTATED.txt\n",
      "03_AR05_24980898_mk_ANNOTATED.txt\n",
      "02_AR03_05_25126038_mk_ANNOTATED.txt\n",
      "03_AR01_21699821_mk_ANNOTATED.txt\n",
      "03_AR04_22379238_mk_ANNOTATED.txt\n",
      "02_AR05_04_23954763_mk_ANNOTATED.txt\n",
      "02_AG05_01_23928891_mk_ANNOTATED.txt\n",
      "02_AR01_05_22379245_mk_ANNOTATED.txt\n",
      "02_AR03_04_25136085_mk_ANNOTATED.txt\n",
      "02_AR01_02_23083918_mk_ANNOTATED.txt\n",
      "02_AR04_03_24470693_mk_ANNOTATED.txt\n",
      "03_AR04_23941878_mk_ANNOTATED.txt\n",
      "03_AR03_25348131_mk_ANNOTATED.txt\n",
      "02_AR04_02_25126029_mk_ANNOTATED.txt\n",
      "03_AR03_25258728_mk_ANNOTATED.txt\n",
      "02_AP04_02_22447249_mk_ANNOTATED.txt\n",
      "02_AR04_01_25142564_mk_ANNOTATED.txt\n",
      "02_LS06_05_23957953_mk_ANNOTATED_IRRELEVANT.txt\n",
      "02_AP08_01_24023823_mk_ANNOTATED.txt\n",
      "02_AR04_04_24333377_mk_ANNOTATED.txt\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ccarey/Documents/Projects/NAMI/rdoc\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "parse_annotations_by_annotator(f_path_plus='./pdfs/all_pdfs_annotated_pmid_names/0', result_dir='./results/tc', annotator='tc')\n",
    "parse_annotations_by_annotator(f_path_plus='./pdfs/all_pdfs_annotated_pmid_names/0', result_dir='./results/mk', annotator='mk')\n",
    "# parse_annotations_by_annotator(f_path_plus='./pdfs/all_pdfs_annotated_pmid_names/0', result_dir='./results/jl', annotator='jl')\n",
    "# parse_annotations_by_annotator(f_path_plus='./pdfs/all_pdfs_annotated_pmid_names/0', result_dir='./results/cc', annotator='cc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd /Users/ccarey/Documents/Projects/NAMI/rdoc/results\n",
    "# ! for d in *; do echo $d; wc -l $d/*; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Need to distinguish positive (green) and negative (red) annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Need to edit results by hand to put in sentence endings and complete sentences as necessary."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
