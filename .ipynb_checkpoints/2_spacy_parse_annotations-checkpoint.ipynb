{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use medic to manage abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# medic requires python3\n",
    "# which python3\n",
    "# /Library/Frameworks/Python.framework/Versions/3.5/bin/python3\n",
    "# which pip3\n",
    "# /Library/Frameworks/Python.framework/Versions/3.5/bin/pip3\n",
    "\n",
    "# installing to /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/\n",
    "\n",
    "# pip3 install sqlalchemy\n",
    "# pip3 install argparse\n",
    "# pip3 install psycopg2\n",
    "# pip3 install medic\n",
    "# pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start\n",
    "# createdb medline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy all pdfs that were annotated so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd /Users/ccarey/Documents/Projects/NAMI/rdoc/pdfs\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cd /Users/ccarey/Documents/Projects/NAMI/rdoc/pdfs\n",
    "# # batch 1\n",
    "# cp ./02_heuristic_2015.07.15/02*IRRELEVANT*  all_pdfs_annotated/\n",
    "# cp ./02_heuristic_2015.07.15/02*ANNOTATED*  all_pdfs_annotated/\n",
    "# # batch 2\n",
    "# cp 20150916_rdoc_project/20151009_in_batch_2/*/*IRRELEVANT* all_pdfs_annotated/\n",
    "# cp 20150916_rdoc_project/20151009_in_batch_2/*/*ANNOTATED* all_pdfs_annotated/\n",
    "# # batch 3\n",
    "# J had marked a couple batch 3 could not annotate or similarly\n",
    "# cp 20151012_rdoc_project/in_batch_3/*/*NOT* all_pdfs_annotated/\n",
    "# cp 20151012_rdoc_project/in_batch_3/*/*IRREL* all_pdfs_annotated/ # none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of batch 3 we want to start with\n",
    "Start with these since we can parse the pubmed id out of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pulling from NCBI using medic\n",
    "Assume that with 'medic update' the records are coming from NCBI eUtils since that is what 'medic insert' would do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = !ls all_pdfs_annotated/ | grep 03_AR.._ | sed 's/03_AR0._//' | sed 's/_.*//' | sort | uniq\n",
    "x = ' '.join(x)\n",
    "cmd = 'medic update {}'.format(x)\n",
    "#!$cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching from our postgres database using medic\n",
    "\n",
    "1 row per record\n",
    "\n",
    "pubmed ID \\t title \\t abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!medic write --format tsv ALL > 03_medic_abstracts.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spacy.io to parse annotation sentences.\n",
    "https://spacy.io/#install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# python -m spacy.en.download all # 400 Mb for parser models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Had to manually fetch tag_map.json\n",
    "First try running spacy, got when trying:\n",
    "\n",
    "$ nlp = English()\n",
    "\n",
    "IOError: [Errno 2] No such file or directory: u'/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/spacy/en/data/vocab/tag_map.json'\n",
    "\n",
    "tag_map.json did not exist, I manually fetched it.\n",
    "\n",
    "https://github.com/honnibal/spaCy/blob/master/lang_data/en/tag_map.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try very basic spacy tokenizer to make sure spacy works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!head -1 03_medic_abstracts.tsv | cut -f3 > temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp wants unicode, so head to substitute .decode('utf8') into the simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Some', u'\\n', u'spaces', u' ', u'and', u'\\t', u'tab', u'characters', u'.', u'and', u'here', u'are', u'some', u'more', u'.']\n"
     ]
    }
   ],
   "source": [
    "from spacy.en import English\n",
    "nlp = English(parser=False)\n",
    "#tokens = nlp('Some\\nspaces  and\\ttab characters')\n",
    "tokens = nlp('Some\\nspaces  and\\ttab characters. and here are some more.'.decode('utf8'))\n",
    "print([t.orth_ for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split sentences, need to have a parser.\n",
    "\n",
    "without a parser installed:\n",
    "\n",
    "    ValueError: sentence boundary detection requires the dependency parse, which requires data to be installed. If you haven't done so, run: \n",
    "    python -m spacy.en.download all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., Here's another...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = English(parser=True)\n",
    "doc = nlp(\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "assert [s.root.orth_ for s in doc.sents] == [\"is\", \"'s\"]\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spacy to split one abstract into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# should get 7 sentences\n",
    "abstract = u'The high comorbidity of posttraumatic stress disorder (PTSD) and alcohol dependence (AD) has been \\\n",
    "firmly established. Although laboratory studies have examined self-reported craving in response to trauma and \\\n",
    "alcohol cues, no studies have reported on alcohol-related physiological responding in response to trauma cues in \\\n",
    "PTSD-AD individuals. Using a cue reactivity paradigm, this study examined the impact of personalized trauma-image \\\n",
    "cues and in vivo alcohol cues on alcohol-related responding (e.g., salivation, craving) in individuals with PTSD \\\n",
    "and AD (n = 40). Participants displayed reactivity to both trauma and alcohol cues when compared to neutral cues, \\\n",
    "including increased self-reported craving and distress, as well as greater salivation. These findings suggest \\\n",
    "that through repeated pairings of trauma memories and alcohol consumption, salivation may become classically \\\n",
    "conditioned to trauma cues. Moreover, the fact that the trauma-alcohol cue combination elicited greater alcohol \\\n",
    "craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol cue \\\n",
    "combinations suggests that effects of the trauma and alcohol cues were additive in nature. Evidence that AD \\\n",
    "individuals with PTSD report increased alcohol craving and display greater salivation in response to trauma \\\n",
    "memories, supplements prior research indicating that PTSD-related negative emotion and trauma-related alcohol \\\n",
    "craving may play an important role in the maintenance of AD.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[The high comorbidity of posttraumatic stress disorder (PTSD) and alcohol dependence (AD) has been firmly established., Although laboratory studies have examined self-reported craving in response to trauma and alcohol cues, no studies have reported on alcohol-related physiological responding in response to trauma cues in PTSD-AD individuals., Using a cue reactivity paradigm, this study examined the impact of personalized trauma-image cues and in vivo alcohol cues on alcohol-related responding (e.g., salivation, craving) in individuals with PTSD and AD (n = 40)., Participants displayed reactivity to both trauma and alcohol cues when compared to neutral cues, including increased self-reported craving and distress, as well as greater salivation., These findings suggest that through repeated pairings of trauma memories and alcohol consumption, salivation may become classically conditioned to trauma cues., Moreover, the fact that the trauma-alcohol cue combination elicited greater alcohol craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol cue combinations suggests that effects of the trauma and alcohol cues were additive in nature., Evidence that AD individuals with PTSD report increased alcohol craving and display greater salivation in response to trauma memories, supplements prior research indicating that PTSD-related negative emotion and trauma-related alcohol craving may play an important role in the maintenance of AD.]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(abstract)\n",
    "print(len(list(doc.sents)))\n",
    "print(list(doc.sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need at least one space following end of sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[These findings suggest that through repeated pairings of trauma memories and alcohol consumption, salivation may become classically conditioned to trauma cues.fact that the trauma-alcohol cue combination elicited greater alcohol craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol cue combinations, suggests that effects of the trauma and alcohol cues were additive in nature.]\n",
      "2\n",
      "[These findings suggest that through repeated pairings of trauma memories and alcohol consumption, salivation may become classically conditioned to trauma cues., fact that the trauma-alcohol cue combination elicited greater alcohol craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol cue combinations, suggests that effects of the trauma and alcohol cues were additive in nature.]\n"
     ]
    }
   ],
   "source": [
    "try_1 = u'These findings suggest that through repeated pairings of trauma memories and alcohol consumption, \\\n",
    "salivation may become classically conditioned to trauma cues.fact that the trauma-alcohol cue combination elicited \\\n",
    "greater alcohol craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol \\\n",
    "cue combinations, suggests that effects of the trauma and alcohol cues were additive in nature.'\n",
    "try_2 = u'These findings suggest that through repeated pairings of trauma memories and alcohol consumption, \\\n",
    "salivation may become classically conditioned to trauma cues. fact that the trauma-alcohol cue combination elicited \\\n",
    "greater alcohol craving, salivary responding, distress, and arousal than either the trauma-neutral or neutral-alcohol \\\n",
    "cue combinations, suggests that effects of the trauma and alcohol cues were additive in nature.'\n",
    "\n",
    "# need at least one space following '.' : 'cues.fact' vs. 'cues. fact'\n",
    "\n",
    "doc = nlp(try_1)\n",
    "print(len(list(doc.sents)))\n",
    "print(list(doc.sents))\n",
    "\n",
    "doc = nlp(try_2)\n",
    "print(len(list(doc.sents)))\n",
    "print(list(doc.sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use spacy to split our batch 3 abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs # to read file as unicode\n",
    "from spacy.en import English\n",
    "nlp = English(parser=True) # so we can sentence parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>>import codecs\n",
    ">>>f = codecs.open(\"test\", \"r\", \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medic_abstracts = 'pdfs/03_medic_abstracts.tsv'\n",
    "\n",
    "with codecs.open(medic_abstracts, 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "abstracts_d = {} \n",
    "for line in lines:\n",
    "    line = line.split('\\t')\n",
    "    doc = nlp(line[2])\n",
    "    abstracts_d.update({line[0]: list(doc.sents)})\n",
    "# for k,v in abstracts_d.items():\n",
    "#     print(k)\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- >>> full medic, spacy pipeline <<< -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save abstracts in medic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import codecs\n",
    "from spacy.en import English\n",
    "nlp = English(parser=True) # so we can sentence parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start postgres if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "server starting\r\n"
     ]
    }
   ],
   "source": [
    "# createdb medline\n",
    "!pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc\n"
     ]
    }
   ],
   "source": [
    "wkdir = '/Users/ccarey/Documents/Projects/NAMI/rdoc'\n",
    "%cd $wkdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All our pubmed based annotation pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './pdfs/all_pdfs_annotated_pmid_names'\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/pdfs/all_pdfs_annotated_pmid_names\n",
      "------74 pubmed ids for medic ----:\n",
      "23088207 25280468 23744445 25348131 23143607 24376698 24933724 25774613 24870123 21957257 24388670 25773639 21849230 24725811 25740534 25734385 25197810 25126038 25834059 20695690 23904684 23503620 25788679 23647728 23709163 24980898 23957953 25913552 25142564 24806675 25258728 24023823 20685988 22379245 23646134 24333377 24293773 24231418 24116095 21319926 24045586 24770625 21699821 24101292 24285346 24804717 25160677 24333745 24359877 24511281 23928891 23954763 22575329 25154749 25036160 25898427 22438994 22379238 20815182 23452958 21531705 24470693 23941878 23083918 23074247 21613467 24740391 25136085 25017671 25261920 23622762 23558179 22447249 25126029\n"
     ]
    }
   ],
   "source": [
    "# pubmed ids from a subset of file names\n",
    "%cd ./pdfs/all_pdfs_annotated_pmid_names\n",
    "pmids = !ls * | sed 's/[0_].*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\)_.*.pdf/\\1/' | sed '/NA/d'\n",
    "nas = !ls * | sed 's/[0_].*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\)_.*.pdf/\\1/' | sed '/NA/!d'\n",
    "pmids = set(pmids)\n",
    "print('------{} pubmed ids for medic ----:'.format(len(pmids)))\n",
    "pmids = ' '.join(pmids)\n",
    "cmd = 'medic update {}'.format(pmids)\n",
    "print(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ medic command ------\n",
      "medic update 23088207 25280468 23744445 25348131 23143607 24376698 24933724 25774613 24870123 21957257 24388670 25773639 21849230 24725811 25740534 25734385 25197810 25126038 25834059 20695690 23904684 23503620 25788679 23647728 23709163 24980898 23957953 25913552 25142564 24806675 25258728 24023823 20685988 22379245 23646134 24333377 24293773 24231418 24116095 21319926 24045586 24770625 21699821 24101292 24285346 24804717 25160677 24333745 24359877 24511281 23928891 23954763 22575329 25154749 25036160 25898427 22438994 22379238 20815182 23452958 21531705 24470693 23941878 23083918 23074247 21613467 24740391 25136085 25017671 25261920 23622762 23558179 22447249 25126029\n",
      "------ medic warnings etc ------\n"
     ]
    }
   ],
   "source": [
    "print('------ medic command ------')\n",
    "print(cmd)\n",
    "print('------ medic warnings etc ------') # seems fine ignoring sqlalchemy warning.\n",
    "\n",
    "#! $cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts_m = !medic --error write --format tsv ALL 2> /dev/null | cut -f1,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts = []\n",
    "type(abstracts)\n",
    "with io.BytesIO(abstracts_m.n) as a:\n",
    "    for line in a.readlines():\n",
    "        pmid, abst = line.split('\\t')\n",
    "        abstracts.append({pmid: abst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spacy_split_sentences(text):\n",
    "    sentences = []\n",
    "    #doc = nlp(text.decode('utf8')) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    doc = nlp(text) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    for span in doc.sents:\n",
    "        #sentences.append(u''.join(doc[i].string for i in range(span.start, span.end)).encode('utf-8').strip())\n",
    "        sentences.append(''.join(doc[i].string for i in range(span.start, span.end)))#.strip())\n",
    "    sentences = '\\n'.join(sentences)\n",
    "    sentences = sentences + '\\n'\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save sentence split abstract for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../../results'\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/results\n",
      "\u001b[34mcc\u001b[m\u001b[m/ \u001b[34mjl\u001b[m\u001b[m/ \u001b[34mmk\u001b[m\u001b[m/ \u001b[34mtc\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "%cd ../../results\n",
    "%ls\n",
    "# cleanup if we are testing\n",
    "# ! rm *.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in abstracts:\n",
    "    fout = a.keys()[0] + '.org'\n",
    "    with codecs.open(fout, 'w', 'utf-8') as f:\n",
    "        body = a.values()[0].decode('utf-8')\n",
    "        body_text = spacy_split_sentences(body)\n",
    "        f.write(body_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply edits one pair of files at a time\n",
    "\n",
    "BASH: Open the files in pairs for easy editing.\n",
    "\n",
    "Note, not every [annotator].org file will have a matching .txt annotation.\n",
    "+ 1) We are just working through files in the ./results/[annotator]/ folders\n",
    "+ 2) Not every .org file had an equivalent annotation by the person.\n",
    "+ 3) some files needed completely manual annotations. and were not in the ./results[annotator]/ folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edit abstracts per annotations\n",
    "Create temporary files in current directory\n",
    "\n",
    "for each file:\n",
    "- edit abstracts in emacs\n",
    "- copy results into subject/who/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem files:\n",
    "Conclusions not included in abstract in \n",
    "  + 23744445\n",
    "\n",
    "Different versions? (fully spelled out abbrevs from pubmed).\n",
    "  + 24285346\n",
    "  \n",
    "A PMID Mislabeled as 23941878 corrected everywhere to 25258728\n",
    "\n",
    "Then we have 25258728 twice, once for AR03 and once for AR04. It is unclear if it should have been in AR04, so delete those, keep only AR03_25258728."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! for f in *[0-9].org; do cp $f ${f/./_jl.}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "this directly in bash so we can step through file one at a time.\n",
    "\n",
    "odir=annotations_processed\n",
    "mkdir \"$odir\"\n",
    "\n",
    "find matching .org to edit for each of subjects files.\n",
    "for j, this handled 42 .org files.\n",
    "for f in ./jl/*_jl_*.txt; do\n",
    "  initials='jl'\n",
    "  echo \"Apply edits to $f\";\n",
    "  bn=$(basename $f)\n",
    "  cp \"$f\" \"$bn\"\n",
    "  # echo \"$bn\"\n",
    "  pmid=$(echo \"$bn\" | sed 's/.*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\).*/\\1/')\n",
    "  open -a emacs \"$bn\"\n",
    "  open \"${pmid}_${initials}.org\"\n",
    "  # edit and save\n",
    "  topic=$(echo \"$bn\" | sed 's/.*\\([A-Z][A-Z][0-9][0-9]\\).*/\\1/')\n",
    "  mkdir -p \"${odir}/${topic}/${initials}\"\n",
    "  fout=\"${odir}/${topic}/${initials}/${pmid}.txt\";\n",
    "  read -p \"Press any key...done #echo \";\n",
    "  echo \"Saving edits to $fout\"\n",
    "  mv \"${pmid}_${initials}.org\" \"$fout\"\n",
    "  rm \"$bn\"\n",
    "  rm \"${pmid}_${initials}.org\"\n",
    "  echo\n",
    "done\n",
    "<\\pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JL: Check how many stranded .org we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['ls: *_jl.org: No such file or directory']\n"
     ]
    }
   ],
   "source": [
    "stranded = !ls *_jl.org | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/'\n",
    "print(len(stranded))\n",
    "print(stranded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JL: check how many processed annotations we had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed=!ls ./annotations_processed/*/jl/*.txt | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/'\n",
    "len(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JL: Check how many total possible annotations we could have had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible=!ls ../pdfs/all_pdfs_annotated_pmid_names/*jl* | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/'\n",
    "len(possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually process the positives amongst the 8 that correspond to stranded .org.\n",
    "\n",
    "41 + 8 = 49.\n",
    "\n",
    "The remaining 1 to get to full 50 possible was not a pubmed document.\n",
    "\n",
    "So we manually processed the straightforward annotations:\n",
    "\n",
    "'_02_AP07_02_24804717_jl_ANNOTATED.pdf',  '_02_LS05_02_20685988_jl_ANNOTATED.pdf',\n",
    "'_02_AR00_03_25788679_jl_ANNOTATED.pdf', '_03_AR03_24806675_jl_ANNOTATED.pdf'\n",
    "\n",
    "and manually the irrelevant as we did for other normal irrelevants...\n",
    "\n",
    "'_02_LS00_03_25913552_jl_IRRELEVANT.pdf',\n",
    "\n",
    "## TODO: Still need to process the IRRELEVANT and MISCLASSIFIEDS\n",
    "'_02_AR00_02_25834059_jl_ANNOTATED_MISCLASSIFIED_CS.pdf',  '_02_AR03_01_25261920_jl_ANNOTATED_MISCLASSIFIED_SSP.pdf', '_02_AR03_03_25160677_jl_ANNOTATED_MISCLASSIFIED_SSPorCS.pdf', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['24804717', '25834059', '25788679', '20685988', '25160677', '25913552', '24806675', '25261920'])\n",
      "\n",
      "['_02_AP07_02_24804717_jl_ANNOTATED.pdf', '_02_AR00_02_25834059_jl_ANNOTATED_MISCLASSIFIED_CS.pdf', '_02_AR00_03_25788679_jl_ANNOTATED.pdf', '_02_AR03_01_25261920_jl_ANNOTATED_MISCLASSIFIED_SSP.pdf', '_02_AR03_03_25160677_jl_ANNOTATED_MISCLASSIFIED_SSPorCS.pdf', '_02_LS00_03_25913552_jl_IRRELEVANT.pdf', '_02_LS05_02_20685988_jl_ANNOTATED.pdf', '_03_AR03_24806675_jl_ANNOTATED.pdf']\n",
      "\n",
      "set(['../pdfs/all_pdfs_annotated_pmid_names/02_AG00_01_NA1_jl_IRRELEVANT.pdf'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# manually annotate these\n",
    "\n",
    "print(set(possible).intersection(set(stranded)))\n",
    "print\n",
    "todo=!ls /Users/ccarey/Documents/Projects/NAMI/rdoc/pdfs/all_pdfs_annotated_pmid_names/_*jl_*\n",
    "print([os.path.basename(x) for x in todo])\n",
    "\n",
    "# a non-pubmed document\n",
    "print\n",
    "print(set(possible).difference(set(processed).union(set(stranded))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: *_jl.org: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# finally cleanup the remaining irrelevant _jl.org \n",
    "!rm *_jl.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! for f in *[0-9].org; do cp $f ${f/./_tc.}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, most of T's IRRELEVANTs are blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\n",
    "for f in ./tc/*_tc_*.txt; do\n",
    "  initials='tc'\n",
    "  echo \"Apply edits to $f\";\n",
    "  bn=$(basename $f)\n",
    "  cp \"$f\" \"$bn\"\n",
    "  # echo \"$bn\"\n",
    "  pmid=$(echo \"$bn\" | sed 's/.*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\).*/\\1/')\n",
    "  open -a emacs \"$bn\"\n",
    "  open \"${pmid}_${initials}.org\"\n",
    "  # edit and save\n",
    "  topic=$(echo \"$bn\" | sed 's/.*\\([A-Z][A-Z][0-9][0-9]\\).*/\\1/')\n",
    "  mkdir -p \"${odir}/${topic}/${initials}\"\n",
    "  fout=\"${odir}/${topic}/${initials}/${pmid}.txt\";\n",
    "  read -p \"Press any key...done #echo \";\n",
    "  echo \"Saving edits to $fout\"\n",
    "  mv \"${pmid}_${initials}.org\" \"$fout\"\n",
    "  rm \"$bn\"\n",
    "  rm \"${pmid}_${initials}.org\"\n",
    "  echo\n",
    "done\n",
    "\n",
    "<\\pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary T\n",
    "\n",
    "- TC: 28 stranded\n",
    "- TC: 45 processed\n",
    "- TC: 51 possible\n",
    "\n",
    "Manually procesing 6\n",
    "\n",
    "- _02_AR00_02_25834059_tc_ANNOTATED.pdf \n",
    "- _02_AR03_03_25160677_tc_ANNOTATED.pdf\n",
    "- _02_AR00_03_25788679_tc_ANNOTATED.pdf\n",
    "- _02_LS05_02_20685988_tc_ANNOTATED.pdf\n",
    "- _02_AR03_01_25261920_tc_ANNOTATED.pdf\n",
    "- _03_AR03_24806675_tc_ANNOTATED.pdf\n",
    "\n",
    "Leaves 22 stranded\n",
    "\n",
    "Note: no 'misclassifieds' or other odd ones like in JL set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! for f in *[0-9].org; do cp $f ${f/./_mk.}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "for f in ./mk/*_mk_*.txt; do\n",
    "  initials='mk'\n",
    "  echo \"Apply edits to $f\";\n",
    "  bn=$(basename $f)\n",
    "  cp \"$f\" \"$bn\"\n",
    "  # echo \"$bn\"\n",
    "  pmid=$(echo \"$bn\" | sed 's/.*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\).*/\\1/')\n",
    "  open -a emacs \"$bn\"\n",
    "  open \"${pmid}_${initials}.org\"\n",
    "  # edit and save\n",
    "  topic=$(echo \"$bn\" | sed 's/.*\\([A-Z][A-Z][0-9][0-9]\\).*/\\1/')\n",
    "  mkdir -p \"${odir}/${topic}/${initials}\"\n",
    "  fout=\"${odir}/${topic}/${initials}/${pmid}.txt\";\n",
    "  read -p \"Press any key...done #echo \";\n",
    "  echo \"Saving edits to $fout\"\n",
    "  mv \"${pmid}_${initials}.org\" \"$fout\"\n",
    "  rm \"$bn\"\n",
    "  rm \"${pmid}_${initials}.org\"\n",
    "  echo\n",
    "done\n",
    "<\\pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary M\n",
    "\n",
    "- MK: 23 stranded\n",
    "- MK: 50 processed\n",
    "- MK: 60 possible\n",
    "\n",
    "Manually procesing 8\n",
    "\n",
    "- _02_AP07_02_24804717_mk_ANNOTATED.pdf\n",
    "- _02_AR00_02_25834059_mk_ANNOTATED.pdf\n",
    "- _02_AR00_03_25788679_mk_ANNOTATED.pdf\n",
    "- _02_AR03_01_25261920_mk_ANNOTATED.pdf\n",
    "- _02_AR03_03_25160677_mk_ANNOTATED.pdf\n",
    "- _02_LS00_03_25913552_mk_ANNOTATED_IRRELEVANT.pdf\n",
    "- _02_LS05_02_20685988_mk_ANNOTATED.pdf\n",
    "- _03_AR03_24806675_mk_ANNOTATED.pdf\n",
    "\n",
    "Leaves 15 stranded\n",
    "\n",
    "Note: no 'misclassifieds' or other odd ones like in JL set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! for f in *[0-9].org; do cp $f ${f/./_cc.}; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "---- cc ---\n",
    "\n",
    "for f in ./cc/*_cc_*.txt; do\n",
    "  initials='cc'\n",
    "  echo \"Apply edits to $f\";\n",
    "  bn=$(basename $f)\n",
    "  cp \"$f\" \"$bn\"\n",
    "  # echo \"$bn\"\n",
    "  pmid=$(echo \"$bn\" | sed 's/.*\\([0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]\\).*/\\1/')\n",
    "  open -a emacs \"$bn\"\n",
    "  open \"${pmid}_${initials}.org\"\n",
    "  # edit and save\n",
    "  topic=$(echo \"$bn\" | sed 's/.*\\([A-Z][A-Z][0-9][0-9]\\).*/\\1/')\n",
    "  mkdir -p \"${odir}/${topic}/${initials}\"\n",
    "  fout=\"${odir}/${topic}/${initials}/${pmid}.txt\";\n",
    "  read -p \"Press any key...done #echo \";\n",
    "  echo \"Saving edits to $fout\"\n",
    "  mv \"${pmid}_${initials}.org\" \"$fout\"\n",
    "  rm \"$bn\"\n",
    "  rm \"${pmid}_${initials}.org\"\n",
    "  echo\n",
    "done\n",
    "<\\pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the annotated abstracts into positive and neutral sentences.\n",
    "\n",
    "For most part, spacy had split the abstracts into 1 sentence per line, so assume that is always the case.\n",
    "\n",
    "Split the sentences by topic and annotator.\n",
    "\n",
    "- Positive sentences : Marked with {{ ... }} either entirely or phrases within the sentences.\n",
    "- Neutral sentences : No {{ ... }} marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/results\n",
      "mkdir: annotations_processed_pos_neut_neg_sentences: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/ccarey/Documents/Projects/NAMI/rdoc/results\n",
    "!mkdir annotations_processed_pos_neut_neg_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: mark up the negative (usually irrelevant but annotated) files.\n",
    "## TODO: process jl remaining complex (negative) files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the topics and subtopics that we have annotations for.\n",
    "\n",
    "Grouping the subtopics should help us have a higher number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AG05', 'AP00', 'AP01', 'AP03', 'AP04', 'AP06', 'AP07', 'AP08', 'AP11', 'AR00', 'AR01', 'AR03', 'AR04', 'AR05', 'AR07', 'LS00', 'LS02', 'LS05', 'LS06', 'LS07', 'LS08']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "topics = glob.glob('annotations_processed/*')\n",
    "topics = [os.path.basename(t) for t in topics]\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by collecting positive, neutral and negative sentences by parent topic by annotator.\n",
    "Remembering to remove blank lines.\n",
    "\n",
    "For instance, out of 412 sentences for MK annotated abstracts for Arousal 201 are marked sentences.\n",
    "#### TODO: redo after marking negative files appropriately\n",
    "### for now negatives will be any sentence in the non-Arousal set for that individual.\n",
    "These negatives include both annotated positive and non-positive sentences from the non-arousal set.\n",
    "\n",
    "i.e. All sentences in loss, whether positive or negative for loss, are counted as negative for purposes of arousal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: ./annotations_processed/AR*/CC/*.txt: No such file or directory\n",
      "ls: ./annotations_processed/*/CC/*.txt: No such file or directory\n",
      "grep: ./annotations_processed/AR*/CC/*.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "annotators = ['JL', 'MK', 'TC', 'CC']\n",
    "for A in annotators:\n",
    "    !grep  -h \"{{\" ./annotations_processed/AR*/{A}/*.txt | sed '/^$/d' > ./annotations_processed/AR_{A}_pos\n",
    "    !ls ./annotations_processed/*/{A}/*.txt | sed '/AR/d' | xargs grep . -h > ./annotations_processed/AR_{A}_neg\n",
    "    !grep -v -h \"{{\" ./annotations_processed/AR*/{A}/*.txt | sed '/^$/d' > ./annotations_processed/AR_{A}_not_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      91 ./annotations_processed/AR_JL_neg\n",
      "      64 ./annotations_processed/AR_JL_not_pos\n",
      "     303 ./annotations_processed/AR_JL_pos\n",
      "     458 total\n",
      "     166 ./annotations_processed/AR_MK_neg\n",
      "     211 ./annotations_processed/AR_MK_not_pos\n",
      "     201 ./annotations_processed/AR_MK_pos\n",
      "     578 total\n",
      "      62 ./annotations_processed/AR_TC_neg\n",
      "     267 ./annotations_processed/AR_TC_not_pos\n",
      "     155 ./annotations_processed/AR_TC_pos\n",
      "     484 total\n",
      "       0 ./annotations_processed/AR_CC_neg\n",
      "       0 ./annotations_processed/AR_CC_not_pos\n",
      "       0 ./annotations_processed/AR_CC_pos\n",
      "       0 total\n"
     ]
    }
   ],
   "source": [
    "for A in annotators: \n",
    "    !wc -l ./annotations_processed/AR_{A}_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wc /Users/ccarey/Documents/Projects/NAMI/rdoc/results/annotations_processed/AR_mk_*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
