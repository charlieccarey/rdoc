{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quick and dirty test Auditory perception whole docs vs. other categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive corpus from all Auditory abstracts\n",
    "- 146 documents in batch_05_AP_pmids (most are actually AP)\n",
    "\n",
    "### Compare Auditory perception to corpus for other topics\n",
    "Decreasing distance:\n",
    "- 1000 disease documents\n",
    "- 1000 arousal documents\n",
    "- 1000 auditory perception documents\n",
    "- 1000 psychology documents, psyc_1000_ids\n",
    "- 156 new arousal documents, batch_04_AR_pmids (most are probably AP, but a few prob are not.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our deepdive app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deepdive_app/my_app/:\n",
    "  - db.url # name for this db\n",
    "  - deepdive.conf # contains extractors, inference rules, specify holdout.\n",
    "  - input/raw_sentences\n",
    "  - input/annotated_sentences\n",
    "  - input/init.sh\n",
    "  - udf/* # user defined functions used within deepdive.conf\n",
    "  \n",
    "Steps to build app:\n",
    "\n",
    "deepdive initdb:\n",
    " - db started with schema\n",
    " - runs init.sh to preload deepdive postgres db with raw, annotated sentences\n",
    "\n",
    "deepdive run:\n",
    " - creates run/* directory for each run\n",
    " - runs deepdive.conf which holds the deepdive pipeline extractors and rules\n",
    "   - in particular, the extractors set up the features and rules to be used by deepdive\n",
    "   \n",
    "We have some of these items as templates in a template directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg_ctl: another server might be running; trying to start server anyway\r\n",
      "server starting\r\n"
     ]
    }
   ],
   "source": [
    "!pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log start # deepdive and medic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception: File exists\r\n"
     ]
    }
   ],
   "source": [
    "templates='/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/templates_deepdive_app_bagofwords'\n",
    "\n",
    "app_dir='/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception'\n",
    "%mkdir {app_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception\n"
     ]
    }
   ],
   "source": [
    "%cd {app_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception: File exists\n",
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception\n"
     ]
    }
   ],
   "source": [
    "%cp -r {templates}/* {app_dir}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# modify the postgres db name\n",
    "# \n",
    "!echo postgresql://localhost/8_0_3_quick_auditory_perception > db.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill input directory based on document abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception/input\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception/input'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping the Auditory perception positive, negative training, and a set of unkowns to test.\n",
    "training set:\n",
    "- 146 documents as postive\n",
    "- 1000 documents as negative\n",
    "\n",
    "our unknowns are a mix of positive, likely negative, most likely negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "abstracts from other topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstracts(pmid_list_file):\n",
    "    abstracts=!medic --format tsv write --pmid-list {pmid_list_file} 2>/dev/null\n",
    "    return([a.split('\\t', 2) for a in abstracts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_146 = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp/batch_05_AP_pmids')\n",
    "ap_1000 = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp/AP00_1000_ids')\n",
    "diss = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp/diss_1000_ids')\n",
    "# psyc = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp/psyc_1000_ids')\n",
    "# ar_1000 = get_abstracts('/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/task_data_temp/AR_1000_ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### annotated sentences\n",
    " my_id   sentences   [tf]    \\N\n",
    " - column 3, true, false, null\n",
    " - column 4 null id for deepdive's use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import codecs\n",
    "from spacy.en import English\n",
    "nlp = English(parser=True, tagger=True) # so we can sentence parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def spacy_lemma_gt_len(text, length=2):\n",
    "    '''Create bag of unique lemmas, requiring lemma length > length\n",
    "    \n",
    "    Note: setting length to 1 may mess up our postgres arrays as we would\n",
    "    get commas here, unless we were to quote everything.\n",
    "    '''\n",
    "    tokens = []\n",
    "    #doc = nlp(text.decode('utf8')) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    parsed_data = nlp(text) #\"This is a sentence. Here's another...\".decode('utf8'))\n",
    "    for token in parsed_data:\n",
    "        if len(token.lemma_) > length:\n",
    "            tokens.append(token.lemma_.lower())\n",
    "    return(list(set(tokens)))\n",
    "\n",
    "# def remove_stop_words():\n",
    "#     pass\n",
    "\n",
    "# def spacy_lemma_biwords_gt_len(text, length=3):\n",
    "#     '''Create bag of unique bi-lemmas, requiring lemma length > length\n",
    "    \n",
    "#     We are crudely eliminating any bi-lemmas that have commas in them to save us in loading postgres arrays.\n",
    "#     '''\n",
    "#     biwords = []\n",
    "#     parsed_data = nlp(text)\n",
    "#     skip_chars = [',', '\"', \"'\"]\n",
    "#     for i in range(1, len(parsed_data) - 1):\n",
    "#         skip = False\n",
    "#         biword = u'{} {}'.format(parsed_data[i].lemma_.lower(), parsed_data[i+1].lemma_.lower())\n",
    "#         if (parsed_data[i].lemma_ in skip_chars or parsed_data[i+1].lemma_ in skip_chars):\n",
    "#             skip = True\n",
    "#         if len(biword) > length and not skip:\n",
    "#             biwords.append(biword)\n",
    "#     return(list(set(biwords)))\n",
    "\n",
    "def get_scored_abstract_bow(abstracts, score):\n",
    "    '''Return annotated bag of words.\n",
    "     my_id   sentences   [tf]    \\N\n",
    "     - score (postgres boolean) :  t f \\N\n",
    "     - column 3, true, false, null.\n",
    "     - column 4 null id for deepdive's use.\n",
    "     - {{}} is to wrap list as postgres array.\n",
    "    '''\n",
    "    results = []\n",
    "    for a in abstracts:\n",
    "        # bow = spacy_lemma_gt_len(a[2].decode('utf8'), length=2)\n",
    "        bow = spacy_lemma_gt_len(a[2].decode('utf-8'), length=2)\n",
    "        # maybe remove stop words\n",
    "        bow = u', '.join(bow)\n",
    "        results.append(u'{}\\t{{{}}}\\t{}\\t{}'.format(a[0], bow, score, '\\N'))\n",
    "    return(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_raw_sentences(fname, annotations, score=None):\n",
    "    '''\n",
    "    Annotations (list of lists) : [[id, title, abstract],...]\n",
    "    score (postgres boolean) :  t f \\N'''\n",
    "    with codecs.open(fname, 'a', encoding = 'utf-8') as f:\n",
    "        for a in annotations:\n",
    "            f.write(u'{}\\t{}\\t{}\\N\\n'.format(a[0], a[2].decode('utf-8'), score))\n",
    "                    \n",
    "def write_annotated_sentences(fname, annotations):\n",
    "    ''' \n",
    "    Annotations (list of strings) : [\"id\\tbagofwords\\tpostgres_boolean\\t\\N\",...]\n",
    "    '''\n",
    "    with codecs.open(fname, 'a', encoding = 'utf-8') as f:\n",
    "        for a in annotations:\n",
    "            a = a.replace('\"', '') # avoid postgres malformed array on unescaped quotes\n",
    "            f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception/input\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception/input'\n",
    "%rm ./raw_sentences\n",
    "write_raw_sentences('raw_sentences', ap_146, 't')\n",
    "write_raw_sentences('raw_sentences', diss, 'f')\n",
    "write_raw_sentences('raw_sentences', ap_1000, '\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_146_pos = get_scored_abstract_bow(ap_146, 't')\n",
    "diss_neg = get_scored_abstract_bow(diss, 'f')\n",
    "ap_1000_null = get_scored_abstract_bow(ap_1000, '\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%rm './annotated_sentences'\n",
    "write_annotated_sentences('annotated_sentences', ap_146_pos)\n",
    "write_annotated_sentences('annotated_sentences', diss_neg)\n",
    "write_annotated_sentences('annotated_sentences', ap_1000_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in Null equivalents for the entire training set.\n",
    "This is so we can see their predictions, whether they are in the holdout fraction or not.\n",
    "Otherwise we can not see the results of the non-holdout portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_raw_sentences('raw_sentences', ap_146, '\\N')\n",
    "write_raw_sentences('raw_sentences', diss, '\\N')\n",
    "\n",
    "ap_146_null = get_scored_abstract_bow(ap_146, '\\N')\n",
    "diss_null = get_scored_abstract_bow(diss, '\\N')\n",
    "write_annotated_sentences('annotated_sentences', ap_146_null)\n",
    "write_annotated_sentences('annotated_sentences', diss_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of how the sentences get into deepdive.\n",
    "input/init.sh is executed when we run deepdive initdb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# contents of input/init.sh\n",
    "deepdive sql \"COPY _raw_sentences FROM STDIN\" < ${APP_HOME}\"/input/raw_sentences\"\n",
    "deepdive sql \"COPY _annotated_sentences FROM STDIN\" < ${APP_HOME}\"/input/annotated_sentences\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init and run deepdive app\n",
    "From the top level of this deepdive app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# on command line\n",
    "deepdive initdb\n",
    "deepdive run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inspect  results\n",
    "1. inspect - deepdive's calibration graphs showing accuracy, holdout and holdout + unknowns (nulls)\n",
    "2. extract and inspect expectation vs test values\n",
    "3. Recall that only the 'holdout' portion of the training data gets an expectation assigned.\n",
    "\n",
    "### How to get reports out on all the training, not just the holdout?\n",
    "Just put all the training back in as nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " has_term | sentence_id |  id  | category | expectation \r\n",
      "----------+-------------+------+----------+-------------\r\n",
      "          | 24386403    | 1900 |        1 |       0.998\r\n",
      "          | 24617559    | 3032 |        1 |           0\r\n",
      " f        | 24902046    |  963 |        1 |           0\r\n",
      "          | 24161466    | 1868 |        1 |           1\r\n",
      "          | 23510647    | 1712 |        1 |           0\r\n",
      "          | 26527069    | 3279 |        1 |           0\r\n",
      " f        | 24286024    |  836 |        1 |           0\r\n",
      "          | 23285949    | 1654 |        1 |           0\r\n",
      "          | 23179223    | 2735 |        1 |       0.004\r\n",
      " f        | 23063979    |  570 |        1 |           0\r\n",
      "(10 rows)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "cmd = ('select has_term,sentence_id,id,category,expectation '\n",
    "       'from  _annotated_sentences_has_term_inference order by random() limit 10')\n",
    "!deepdive sql \"{cmd}\"\n",
    "# output tsv\n",
    "# !deepdive sql eval \"{cmd}\" format=tsv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " has_term | sentence_id |  id  | category | expectation\n",
    "----------+-------------+------+----------+-------------\n",
    "          | 23117535    | 1617 |        1 |       0.012\n",
    " t        | 21305666    |   53 |        1 |           1\n",
    "          | 23128585    | 1619 |        1 |       0.908\n",
    "          | 23442569    | 1691 |        1 |       0.312\n",
    "          | 24793771    | 1971 |        1 |           1\n",
    " f        | 23423257    |  653 |        1 |           0\n",
    " f        | 24659875    |  913 |        1 |           0\n",
    "          | 23432759    | 1687 |        1 |       0.034\n",
    "          | 24383225    | 1893 |        1 |       0.076\n",
    "          | 22790547    | 1554 |        1 |       0.808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running deepdive another time, get different holdouts.\n",
    "- The holdout fraction in the deepdive.conf file hasn't changed.\n",
    "- The holdout fraction seems to simply be a rough guide.\n",
    "- There is nothing in documentation about specifying the random seed or how the random selection is made."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ deepdive initdb\n",
    "$ deepdive run\n",
    "$ deepdive sql 'select has_term,sentence_id,id,category,expectation from  _annotated_sentences_has_term_inference' | cut -f1 -d'|' |  sort | uniq -c\n",
    "   1\n",
    "2146\n",
    " 250  f\n",
    "   1  has_term\n",
    "  37  t\n",
    "   1 (2433 rows)\n",
    "   1 ----------+-------------+------+----------+-------------\n",
    "\n",
    "$ deepdive initdb\n",
    "$ deepdive run\n",
    "$ deepdive sql 'select has_term,sentence_id,id,category,expectation from  _annotated_sentences_has_term_inference' | cut -f1 -d'|' |  sort | uniq -c\n",
    "   1\n",
    "2146\n",
    " 259  f\n",
    "   1  has_term\n",
    "  33  t\n",
    "   1 (2433 rows)\n",
    "   1 ----------+-------------+------+----------+-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review our expected input numbers\n",
    "Yes, everything checks out. We have duplicates due to the pseudolabeling of the training test. And a few duplicates due to not having cleaned up our 1000 unknown-to-predict set that might have overlapped with the training set.\n",
    "\n",
    "1146 training records, 146 true, 1000 false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3292  687066 4742740 input/raw_sentences\r\n"
     ]
    }
   ],
   "source": [
    "!wc input/raw_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2134    2134   19206\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 input/raw_sentences | sort | uniq | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2134    2134   19206\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 input/annotated_sentences | sort | uniq | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1146    2292   16044\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 input/raw_sentences | sort | uniq -c | sort | grep -v ' 1 ' | wc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not shown: 12 in the training set were also in the 1000 to be predicted set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1146    1146   10314\r\n"
     ]
    }
   ],
   "source": [
    "!cut -f1 input/raw_sentences | sort | uniq -c | sort | grep -v ' 1 '  | sed 's/ *. //' > mult_rec_pmids\n",
    "!cut -f1 input/raw_sentences | sort | uniq -c | sort | grep -v ' 1 '  | sed 's/ *. //' | wc # number training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2292    6876   37818\r\n"
     ]
    }
   ],
   "source": [
    "#!grep -h -f mult_rec_pmids input/raw_sentences input/annotated_sentences | cut -f1,3 | sort | uniq -c | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pull out clean results sets of the full training and unkown test sets."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                     Table \"public._raw_sentences\"\n",
    "   Column    | Type | Modifiers | Storage  | Stats target | Description\n",
    "-------------+------+-----------+----------+--------------+-------------\n",
    " sentence_id | text |           | extended |              |\n",
    " sentence    | text |           | extended |              |\n",
    " terms       | text |           | extended |              |\n",
    "\n",
    "           View \"public._annotated_sentences_has_term_inference\"\n",
    "   Column    |       Type       | Modifiers | Storage  | Description\n",
    "-------------+------------------+-----------+----------+-------------\n",
    " sentence_id | text             |           | extended |\n",
    " words       | text[]           |           | extended |\n",
    " has_term    | boolean          |           | plain    |\n",
    " id          | bigint           |           | plain    |\n",
    " category    | bigint           |           | plain    |\n",
    " expectation | double precision |           | plain    |\n",
    "\n",
    "category is all 1 (we had a single category prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:  table \"cc_neg_holdout\" does not exist\n",
      "DROP TABLE\n",
      "DROP TABLE\n"
     ]
    }
   ],
   "source": [
    "fields = 'terms,has_term,sentence_id,expectation,sentence'\n",
    "\n",
    "!deepdive sql 'DROP TABLE cc_neg_holdout'\n",
    "!deepdive sql 'DROP TABLE cc_pos_holdout'\n",
    "!deepdive sql 'DROP TABLE cc_training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_holdout = ('SELECT DISTINCT r.terms,has_term,a.sentence_id,expectation INTO '\n",
    "               'cc_neg_holdout FROM '\n",
    "               '_annotated_sentences_has_term_inference as a JOIN '\n",
    "               '_raw_sentences as r ON '\n",
    "               'a.sentence_id = r.sentence_id WHERE '\n",
    "               'NOT a.has_term '\n",
    "               'ORDER BY a.sentence_id') # if include r.terms would see we pseudonulled all these.\n",
    "pos_holdout = ('SELECT DISTINCT r.terms,has_term,a.sentence_id,expectation INTO '\n",
    "               'cc_pos_holdout FROM '\n",
    "               '_annotated_sentences_has_term_inference as a JOIN '\n",
    "               '_raw_sentences as r ON '\n",
    "               'a.sentence_id = r.sentence_id WHERE '\n",
    "               'a.has_term '\n",
    "               'ORDER BY a.sentence_id') # if include r.terms would see we pseudonulled all these.\n",
    "\n",
    "# test = (\"SELECT DISTINCT r.terms,a.has_term,a.sentence_id,a.expectation FROM \"\n",
    "#                \"_annotated_sentences_has_term_inference as a JOIN \"\n",
    "#                \"_raw_sentences as r ON \"\n",
    "#                \"a.sentence_id = r.sentence_id JOIN \"\n",
    "#                \"cc_neg_holdout as n ON a.sentence_id = n.sentence_id WHERE \"\n",
    "#                \"a.has_term IS NULL AND r.terms IS NOT NULL \"\n",
    "#                \"ORDER BY a.sentence_id\") # 259\n",
    "\n",
    "pos_neg_input = (\"SELECT DISTINCT r.terms,a.has_term,a.sentence_id,a.expectation INTO \"\n",
    "                 \"cc_all_input FROM \"\n",
    "               \"_annotated_sentences_has_term_inference as a JOIN \"\n",
    "               \"_raw_sentences as r ON \"\n",
    "               \"a.sentence_id = r.sentence_id LEFT JOIN \"\n",
    "               \"cc_neg_holdout as n ON a.sentence_id = n.sentence_id WHERE \"\n",
    "               \"a.has_term IS NULL AND r.terms IS NOT NULL \"\n",
    "               \"ORDER BY a.sentence_id\")\n",
    "\n",
    "training = (\"SELECT DISTINCT a.terms,a.has_term,a.sentence_id,a.expectation INTO \"\n",
    "            \"cc_training FROM \"\n",
    "               \"cc_all_input as a LEFT JOIN \"\n",
    "               \"cc_pos_holdout as p ON \"\n",
    "               \"a.sentence_id = p.sentence_id LEFT JOIN \"\n",
    "               \"cc_neg_holdout as n ON \"\n",
    "               \"a.sentence_id = n.sentence_id WHERE \"\n",
    "               \"p.sentence_id IS NULL AND n.sentence_id IS NULL AND a.terms IS NOT NULL\")\n",
    "\n",
    "report = \"select * from cc_pos_holdout UNION ALL select cc_pos_holdout\" # as p union all select t.terms from cc_training as t\"\n",
    "\n",
    "# report = (\"SELECT * \"\n",
    "#                \"cc_all_input UNION ALL \"\n",
    "#                \"SELECT * FROM cc_pos_holdout UNION ALL \"\n",
    "#                \"SELECT * FROM cc_training \")\n",
    "#                 WHERE \"\n",
    "#                \"c.has_term IS NULL AND r.terms IS NOT NULL \"\n",
    "#                \"ORDER BY a.sentence_id\")\n",
    "\n",
    "# unk_input = (\"SELECT DISTINCT r.terms,has_term,a.sentence_id,category,expectation FROM \"\n",
    "#                \"_annotated_sentences_has_term_inference as a JOIN \"\n",
    "#                \"_raw_sentences as r ON \"\n",
    "#                \"a.sentence_id = r.sentence_id\")\n",
    "#result=!deepdive sql \"{neg_holdout}\"\n",
    "#result=!deepdive sql \"{pos_holdout}\"\n",
    "#pos_neg_input_results=!deepdive sql \"{pos_neg_input}\" # should be 1000\n",
    "###unk_input_results=!deepdive sql \"{unk_input}\" # should be 1000\n",
    "#test=!deepdive sql \"{test}\"\n",
    "#test = !deepdive sql \"{training}\"\n",
    "test = !deepdive sql \"{report}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ERROR:  column \"cc_pos_holdout\" does not exist',\n",
       " 'LINE 1: select * from cc_pos_holdout UNION ALL select cc_pos_holdout',\n",
       " '                                                      ^']"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test))\n",
    "test[0:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_training = 'select has_term,sentence_id,category,expectation from _annotated_sentences_has_term_inference as a  WHERE NOT a.has_term'\n",
    "\n",
    "cmd = ('select {} FROM '\n",
    "       '_annotated_sentences_has_term_inference as a JOIN '\n",
    "       '_raw_sentences as r ON '\n",
    "       'a.sentence_id = r.sentence_id WHERE'.format(fields))\n",
    "results=!deepdive sql eval \"{cmd}\" format=tsv\n",
    "fields = fields.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(fields)\n",
    "#results[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot our curves by getting predictions from deepdive by sql.\n",
    "Holdout data has_term is t or f\n",
    "\n",
    "    Total returned = holdout + null labeled trues + null labeled falses + to be predicteds\n",
    "    2438 = (259f + 33t) + 146 + 1000 + 1000\n",
    "\n",
    "As sentences (pubmed ids) are shared between classe:\n",
    "- remove the holdouts (they are retained in the pseudo-null labeled classes)\n",
    "- extract correct labels onto the pseudo-null\n",
    "  - maybe by queries back to _annotated_sentences\n",
    "- remove any 'to be predicteds' that are also in the pseudo-null\n",
    "  - because we hadn't cleaned these out prior to building our input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmd = ('SELECT has_term,sentence_id,id,category,expectation '\n",
    "       'FROM _annotated_sentences_has_term_inference, _annotated_sentences')\n",
    "deepdive sql 'select has_term,sentence_id,id,category,expectation from  _annotated_sentences_has_term_inference' \n",
    "pdrx = !deepdive sql eval \"{cmd}\" format=tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2438\n"
     ]
    }
   ],
   "source": [
    "print(len(pdrx))\n",
    "# Total returned = holdout + null labeled trues + null labeled falses + to be predicteds\n",
    "# 2438 = (259f + 33t) + 146 + 1000 + 1000"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The R Script is in appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception\n"
     ]
    }
   ],
   "source": [
    "%cd '/Users/ccarey/Documents/Projects/NAMI/rdoc/tasks/deepdive_app/8_0_3_quick_auditory_perception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%alias  plot_cal /Users/ccarey/Documents/Projects/NAMI/rdoc/scripts/plot_deepdive_calibration.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%plot_cal ./run/LATEST/calibration/_annotated_sentences.has_term.tsv custom_stats_plots/test > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "images are loaded from the root of the notebook rather than the current directory\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=./tasks/deepdive_app/8_0_3_quick_auditory_perception/custom_stats_plots/test_histogram.png width=350 height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# side by side\n",
    "# <tr>\n",
    "# <td><img src=./tasks/deepdive_app/8_0_3_quick_auditory_perception/custom_stats_plots/test_histogram.png width=200 height=200 /> </td>\n",
    "# <td><img src=./tasks/deepdive_app/8_0_3_quick_auditory_perception/custom_stats_plots/test_stacked_histogram.png /> </td> \n",
    "# </tr>\n",
    "# or \n",
    "# ![my image]./tasks/deepdive_app/8_0_3_quick_auditory_perception/custom_stats_plots/test_stacked_histogram.png\n",
    "# or (also works for pdf) \n",
    "from IPython.display import HTML \n",
    "HTML('<iframe src=./tasks/deepdive_app/8_0_3_quick_auditory_perception/custom_stats_plots/test_histogram.png width=350 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Appendix 1. In R, plot our own curves from deepdive's calibration\n",
    "\n",
    "DeepDive produces some diagnostics.\n",
    "\n",
    "- *calibration/....png*. But can't distinguish the holdouts from the predictions on the unkowns in DeepDive's png.\n",
    "\n",
    "- *calibration/....tsv*. See deepdive documentation.\n",
    "\n",
    "tsv columns:\n",
    "\n",
    "    [bucket_from] [bucket_to] [num_predictions] [num_true] [num_false]\n",
    "\n",
    "- buckets are the min and max extent of the probability bins. (1.00 = 100% probability document is on topic).\n",
    "- Columns 3 is predicted from unknowns + holdouts\n",
    "- Columns 4 and 5 are predicted only from the holdouts."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#!/usr/bin/env Rscript\n",
    "#------------------------------------------------------------------\n",
    "#\n",
    "# Plot a calibration curve for deepdive.\n",
    "#\n",
    "# Usage:\n",
    "#\n",
    "#    Rscript --vanilla plot_deepdive_calibration.R my_dd_predictions.tsv ofile\n",
    "#\n",
    "#------------------------------------------------------------------\n",
    "library(ggplot2)\n",
    "\n",
    "args = commandArgs(trailingOnly=TRUE)\n",
    "ifile = args[1]\n",
    "ofile_stem = args[2]\n",
    "\n",
    "print(paste('Reading :', ifile))\n",
    "\n",
    "t <- read.table(args[1])\n",
    "t$V6 <- t$V3 - t$V4 - t$V5\n",
    "\n",
    "\n",
    "pos_lab = 'Positive training'\n",
    "neg_lab = 'Negative training'\n",
    "neut_lab = 'Unknown' # includes pseudolabeled unkowns (i.e. were labeled positive / negative, but now unkown for prediction)\n",
    "\n",
    "pos <- cbind.data.frame(class=pos_lab, bin=t$V1 + 0.1, count=t$V4)\n",
    "neg <- cbind.data.frame(class=neg_lab, bin=t$V1 + 0.1, count=t$V5)\n",
    "n <- cbind.data.frame(class=neut_lab, bin=t$V1 + 0.1, count=t$V6)\n",
    "all <- rbind.data.frame(neg,n,pos)\n",
    "\n",
    "\n",
    "print(paste0('Writing results to : ', ofile, '_histogram.pdf'))\n",
    "\n",
    "pdf(paste0(ofile, '_histogram.pdf'))\n",
    "ggplot(all, aes(x=as.character(bin), y=count, fill=class, xlab='probability bin')) +\n",
    "  geom_bar(stat='identity', position='dodge') +\n",
    "  ggtitle('histogram') +\n",
    "  xlab('probability bin')\n",
    "dev.off()\n",
    "\n",
    "print(paste0('Writing results to : ', ofile, '_stacked_histogram.pdf'))\n",
    "\n",
    "pdf(paste0(ofile, '_stacked_histogram.pdf'))\n",
    "ggplot(all, aes(x=bin, y=count, fill = class)) + \n",
    "  geom_bar(stat = \"identity\") + \n",
    "  ggtitle('Stacked histogram') +\n",
    "  xlab('input class')\n",
    "dev.off()\n",
    "\n",
    "#plot(x=t$V1+0.1, y=t$V3, xlim = c(0,1), ylim = c(0,max(t)), col = 'grey', main='calibration curve deepdive documentation')\n",
    "# points(x=t$V1+0.1, y=t$V4, col = 'blue')\n",
    "# points(x=t$V1+0.1, y=t$V5, col = 'red')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
